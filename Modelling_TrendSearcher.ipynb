{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60db2989",
   "metadata": {
    "id": "60db2989"
   },
   "source": [
    "##  <font color='273469'> Product Trend Analysis: Amazon Reviews in the Personal Care Vertical <font><a class='anchor' id='top'></a>\n",
    " ===== </br>\n",
    " **Author:** Stephanie Lo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe321703",
   "metadata": {
    "id": "fe321703"
   },
   "source": [
    "### <font color='256D85'>Table of contents<font><a class='anchor' id='top'></a>\n",
    "\n",
    "1. [Introduction to the notebook](#1)</br>\n",
    "2. [Loading Finalized Data](#2)</br>\n",
    "    a.[Splitting data into train and test](#2.a)</br>\n",
    "    b.[Setting up the Column Transformer](#2.b)</br>\n",
    "3. [Modelling](#3)</br>\n",
    "    a.[Logistic Regression](#3.a)</br>\n",
    "    b.[Support Vector Machine](#3.b)</br>\n",
    "    c.[Random Forest](#3.c)</br>\n",
    "    d.[XGBoost](#3.d)</br>\n",
    "4. [Model Evaluation](#4)</br>\n",
    "    a.[Deciding between Random Forest and XGBoost](#4.a)</br>\n",
    "    b.[Random Forest Interpretability](#4.b)</br>\n",
    "    c.[Applying the machine learning algorithm with product description](#4.c)</br>\n",
    "    d.[The Final Model](#4.d)</br>\n",
    "5. [Conclusion to the notebook](#5)</br>\n",
    "    a.[Final Thoughts](#5.a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06038b9",
   "metadata": {},
   "source": [
    "## <font color='256D85'> Introduction to this notebook  <font>  <a id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8779f6",
   "metadata": {},
   "source": [
    "This notebook will perform the modelling process and model evaluation in order to choose the best model for our project trend searcher. To conclude, we will evaluate what the next steps would be to implement this model in practice. Please note that this notebook was run with an Amazon Sagemaker instance so there will be some markdown speaking to this process. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe8351",
   "metadata": {},
   "source": [
    "##  <font color='256D85'> Loading Finalized Data <font> <a id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be91aefc",
   "metadata": {},
   "source": [
    "In this section we will be reading in the finalized data set that we worked on over the past two notebooks. This contains the combined dataset of both product metadata and review data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47bba446",
   "metadata": {
    "id": "47bba446"
   },
   "outputs": [],
   "source": [
    "#importing base packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import joblib\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "#loading in data visualization packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#loading in amazon-specific package\n",
    "import boto3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1b3fe4ab",
   "metadata": {
    "id": "1b3fe4ab"
   },
   "outputs": [],
   "source": [
    "#Setting figure size & background for the notebook\n",
    "plt.rcParams['figure.figsize'] = (8.0, 6.0)\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1d7b19",
   "metadata": {},
   "source": [
    "The code below is optional if you wanted to access the file from the S3 bucket, however for this notebook we will read in the data frame locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56c1613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the doc strings if you want to activate a sagemaker instance\n",
    "\"\"\"\n",
    "# Instantiate an S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Check the client has been activate. \n",
    "s3_client\n",
    "\n",
    "# Setting the bucket and file name \n",
    "bucket_name = 'deliverable-slo-bstn-bucket'\n",
    "file_path = 'clean_data.csv'\n",
    "\n",
    "# Use the S3 client to get the object\n",
    "response = s3_client.get_object(Bucket=bucket_name, Key=file_path)\n",
    "# Read the object data into a Pandas DataFrame\n",
    "df_combined = pd.read_csv(response['Body'])\n",
    "df_combined = df_combined.drop(columns =\"Unnamed: 0\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e56d9af",
   "metadata": {
    "id": "8e56d9af"
   },
   "outputs": [],
   "source": [
    "#directing to the right file path\n",
    "os.chdir(\"data/CAPSTONE/clean/\")\n",
    "cwd = os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3429c40c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "3429c40c",
    "outputId": "fb3d1d35-9b00-428a-b596-f39fec6dc0b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>trending_asin</th>\n",
       "      <th>price_USD</th>\n",
       "      <th>ranking</th>\n",
       "      <th>product_description</th>\n",
       "      <th>also_buy_counts</th>\n",
       "      <th>also_view_counts</th>\n",
       "      <th>...</th>\n",
       "      <th>m_Pureology</th>\n",
       "      <th>m_RUSK</th>\n",
       "      <th>m_Red Flower</th>\n",
       "      <th>m_Rene Furterer</th>\n",
       "      <th>m_Stila</th>\n",
       "      <th>m_StriVectin</th>\n",
       "      <th>m_TS</th>\n",
       "      <th>m_The Art of Shaving</th>\n",
       "      <th>m_Vichy</th>\n",
       "      <th>m_theBalm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bought for my daughter.</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4324.0</td>\n",
       "      <td>After a long day of handling thorny situations...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  vote  verified               reviewText  trending_asin  price_USD   \n",
       "0      5.0   0.0         1  Bought for my daughter.              0       30.0  \\\n",
       "\n",
       "   ranking                                product_description   \n",
       "0   4324.0  After a long day of handling thorny situations...  \\\n",
       "\n",
       "   also_buy_counts  also_view_counts  ...  m_Pureology  m_RUSK  m_Red Flower   \n",
       "0             56.0              48.0  ...          0.0     0.0           0.0  \\\n",
       "\n",
       "   m_Rene Furterer  m_Stila  m_StriVectin  m_TS  m_The Art of Shaving   \n",
       "0              0.0      0.0           0.0   0.0                   0.0  \\\n",
       "\n",
       "   m_Vichy  m_theBalm  \n",
       "0      0.0        0.0  \n",
       "\n",
       "[1 rows x 62 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in the datasets\n",
    "df_combined = pd.read_csv(\"clean_data.csv\").drop(columns =\"Unnamed: 0\")\n",
    "df_combined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e7315ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e7315ae",
    "outputId": "4dfcf2b5-efed-458b-868a-6d10b4829679"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final data shape contains 137885 columns and 62 rows\n"
     ]
    }
   ],
   "source": [
    "print(f\"The final data shape contains {df_combined.shape[0]} columns and {df_combined.shape[1]} rows\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b89950",
   "metadata": {
    "id": "d7b89950"
   },
   "source": [
    "#### Null and Duplicate Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75fbd0",
   "metadata": {
    "id": "0c75fbd0"
   },
   "source": [
    "Now that we have our dataset read through it's best practice to do a quick check for any nulls or duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522169ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "522169ae",
    "outputId": "5cf869a4-cfd9-428a-ee10-946f0b26bf37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values: 0\n",
      "Duplicated values: 0\n"
     ]
    }
   ],
   "source": [
    "#null and duplicate value check \n",
    "null_check = df_combined.isna().sum().sum()\n",
    "duplicate_check = df_combined.duplicated().sum()\n",
    "\n",
    "print(f\"Null values: {null_check}\")\n",
    "print(f\"Duplicated values: {duplicate_check}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc6ea24",
   "metadata": {
    "id": "afc6ea24"
   },
   "source": [
    "Looks like the dataset is completely clean so let's split out our data into train and test splits. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce6b6e",
   "metadata": {
    "id": "bcce6b6e"
   },
   "source": [
    "### <font color='256D85'> Splitting data into train and test <font> <a id=#2.a></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "663649cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting XGBoost\n",
      "  Downloading xgboost-1.7.5-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from XGBoost) (1.10.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from XGBoost) (1.22.3)\n",
      "Installing collected packages: XGBoost\n",
      "Successfully installed XGBoost-1.7.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "99483aa2",
   "metadata": {
    "id": "99483aa2"
   },
   "outputs": [],
   "source": [
    "# sci-kit learn loading\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# The classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "  #activate if using the Sagemaker instance since XGboost is not included in the base python package and needs to be installed\n",
    "#model evaluation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, roc_curve, roc_auc_score, RocCurveDisplay, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aabc9b6",
   "metadata": {
    "id": "7aabc9b6"
   },
   "source": [
    "In this notebook, we will be running our initial models with what we have defined as our most important column containing text, `reviewText`, we can create a copy of the finalized data set so that we maintain the integrity of both models which are named as follows:\n",
    "1. df: model with `reviewText`\n",
    "2. df_with_desc: model with `reviewText` and `product_description`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25765d9d",
   "metadata": {
    "id": "25765d9d"
   },
   "outputs": [],
   "source": [
    "#creating two copies of the final dataframe\n",
    "df_with_desc = df_combined.copy()\n",
    "df = df_combined.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dadc231e",
   "metadata": {
    "id": "dadc231e"
   },
   "outputs": [],
   "source": [
    "#dropping remaining text column for df\n",
    "columns = ['product_description']\n",
    "for column in columns: \n",
    "     df= df_combined.drop([column],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83d17b1b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "83d17b1b",
    "outputId": "5a3eb180-ca00-4a59-98c2-32898cc1e99a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>trending_asin</th>\n",
       "      <th>price_USD</th>\n",
       "      <th>ranking</th>\n",
       "      <th>also_buy_counts</th>\n",
       "      <th>also_view_counts</th>\n",
       "      <th>c_accessories</th>\n",
       "      <th>...</th>\n",
       "      <th>m_Pureology</th>\n",
       "      <th>m_RUSK</th>\n",
       "      <th>m_Red Flower</th>\n",
       "      <th>m_Rene Furterer</th>\n",
       "      <th>m_Stila</th>\n",
       "      <th>m_StriVectin</th>\n",
       "      <th>m_TS</th>\n",
       "      <th>m_The Art of Shaving</th>\n",
       "      <th>m_Vichy</th>\n",
       "      <th>m_theBalm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45233</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Awesome! So worth the money!</td>\n",
       "      <td>0</td>\n",
       "      <td>139.95</td>\n",
       "      <td>3759.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall  vote  verified                    reviewText  trending_asin  \\\n",
       "45233      5.0   2.0         1  Awesome! So worth the money!              0   \n",
       "\n",
       "       price_USD  ranking  also_buy_counts  also_view_counts  c_accessories  \\\n",
       "45233     139.95   3759.0             18.0               0.0            1.0   \n",
       "\n",
       "       ...  m_Pureology  m_RUSK  m_Red Flower  m_Rene Furterer  m_Stila  \\\n",
       "45233  ...          0.0     0.0           0.0              0.0      0.0   \n",
       "\n",
       "       m_StriVectin  m_TS  m_The Art of Shaving  m_Vichy  m_theBalm  \n",
       "45233           0.0   0.0                   0.0      0.0        0.0  \n",
       "\n",
       "[1 rows x 61 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fac276",
   "metadata": {
    "id": "45fac276"
   },
   "source": [
    "For the following modelling section we will only be working with the `reviewText` column to process through the Tf-idf vectorizer. Let's split out this data frame into train, validation, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a82abcc7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a82abcc7",
    "outputId": "8d6142e0-4d03-4e4a-aad0-a986b890c3ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remainder shape: (96519, 61)\n",
      "Test shape: (41366, 61)\n"
     ]
    }
   ],
   "source": [
    "#for Train test split into remainder and test \n",
    "y = df_combined[\"trending_asin\"]\n",
    "remainder1, test1  = train_test_split(df, test_size=0.3, stratify= y, random_state = 8)\n",
    "print(f\"Remainder shape: {remainder1.shape}\")\n",
    "print(f\"Test shape: {test1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "99c2adbb",
   "metadata": {
    "id": "99c2adbb"
   },
   "outputs": [],
   "source": [
    "#assigning remainder dataset for X and y \n",
    "y_remainder1 = remainder1[\"trending_asin\"]\n",
    "X_remainder1  = remainder1.drop([\"trending_asin\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "98028e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (67563, 60)\n",
      "Validation shape (28956, 60)\n"
     ]
    }
   ],
   "source": [
    "#for train/validation split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train1, X_val1, y_train1, y_val1 = train_test_split(X_remainder1, y_remainder1, test_size=0.3, random_state=1, stratify=y_remainder1)\n",
    "print(f\"Train shape {X_train1.shape}\")\n",
    "print(f\"Validation shape {X_val1.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d84115",
   "metadata": {},
   "source": [
    "Something we also need to create is a sample dataset of the remainder dataset since some models, most notably Support Vector Machine (a distance-based modelling method)is very computationally expensive so in order to speed up the process this sample dataset will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "95469997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remainder sample shape (19303, 61)\n"
     ]
    }
   ],
   "source": [
    "#For sample split\n",
    "from sklearn.model_selection import train_test_split\n",
    "y_sample = remainder1[\"trending_asin\"]\n",
    "remainder1_sample, none1 = train_test_split(remainder1, test_size=0.8, stratify= y_sample, random_state = 8)\n",
    "print(f\"Remainder sample shape {remainder1_sample.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fed25ab",
   "metadata": {},
   "source": [
    "Let's define our target and feature columns with the feature being against `trending_asin`, so that they are ready for modelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "83e7ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining sample dataset from remainder\n",
    "y_remainder1_sample = remainder1_sample[\"trending_asin\"]\n",
    "X_remainder1_sample = remainder1_sample.drop([\"trending_asin\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "50f84ae4",
   "metadata": {
    "id": "50f84ae4"
   },
   "outputs": [],
   "source": [
    "#assigning train dataset for X and y \n",
    "y_test1 = test1[\"trending_asin\"]\n",
    "X_test1  = test1.drop([\"trending_asin\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ebd777",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46ebd777",
    "outputId": "25bc64ac-76ca-4d39-a654-3d014ab15af3"
   },
   "source": [
    "Although we have stratified our data in the train/test splits which maintains the same class balance as the original data set, we can just double-check this quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "308a6691",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "308a6691",
    "outputId": "9eb11a0b-4c9a-4879-ad15-a1cc011a079a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportions in original data:\n",
      "0    0.888559\n",
      "1    0.111441\n",
      "Name: trending_asin, dtype: float64 \n",
      "\n",
      "Proportions in remainder set:\n",
      "0    0.888561\n",
      "1    0.111439\n",
      "Name: trending_asin, dtype: float64 \n",
      "\n",
      "Proportions in test set:\n",
      "0    0.888556\n",
      "1    0.111444\n",
      "Name: trending_asin, dtype: float64 \n",
      "\n",
      "Proportions in train set:\n",
      "0    0.888563\n",
      "1    0.111437\n",
      "Name: trending_asin, dtype: float64 \n",
      "\n",
      "Proportions in validation set:\n",
      "0    0.888555\n",
      "1    0.111445\n",
      "Name: trending_asin, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Proportions in original data:')\n",
    "print(y.value_counts(normalize=True), '\\n')\n",
    "\n",
    "print('Proportions in remainder set:')\n",
    "print(y_remainder1.value_counts(normalize=True), '\\n')\n",
    "\n",
    "print('Proportions in test set:')\n",
    "print(y_test1.value_counts(normalize=True), '\\n')\n",
    "\n",
    "print('Proportions in train set:')\n",
    "print(y_train1.value_counts(normalize=True), '\\n')\n",
    "\n",
    "print('Proportions in validation set:')\n",
    "print(y_val1.value_counts(normalize=True), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b30e2b",
   "metadata": {},
   "source": [
    "This looks good we can now define what columns can go through the column transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdcd7b1",
   "metadata": {
    "id": "2cdcd7b1"
   },
   "source": [
    "### <font color='256D85'> Setting up Column Transformer and Pipeline <font> <a id=\"2.b\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1069a88d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "1069a88d",
    "outputId": "80284d6e-0054-4cd7-831a-318c014e6446"
   },
   "source": [
    "In this section we will be defining what columns we want to carry out with which specific actions which we can do by applying a column transformer. The column transformer helps to apply different transformation for particular columns and is useful when you have a mixture of text and numerical features. In our case, we aim to assign the following: \n",
    "- `reviewText` will be the only column to pass through the Tf-idf vectorizer that we established in notebook two as being the most relevant initial column.  \n",
    "- The rest of the columns which are now in numerical format will be passed through a standard scaler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "020ad699",
   "metadata": {
    "id": "020ad699"
   },
   "outputs": [],
   "source": [
    "#capturing numerical features\n",
    "num_features = df.select_dtypes(include=['int64','float64']).columns\n",
    "num_features = num_features.drop(\"trending_asin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6986519",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "id": "c6986519",
    "outputId": "d256f34e-d017-4b2c-e6d7-630822b84dad"
   },
   "outputs": [],
   "source": [
    "#defining the column transformer\n",
    "ct = ColumnTransformer([\n",
    "        ('tfidf', TfidfVectorizer( stop_words=\"english\",min_df=0.03), 'reviewText'),\n",
    "        ('scale' , StandardScaler(), num_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a18b9d0",
   "metadata": {},
   "source": [
    "After having defined our column transformer we are ready for the modelling process. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f121f33",
   "metadata": {
    "id": "4f121f33"
   },
   "source": [
    "## <font color='256D85'> Modelling <font> <a id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff55ac2",
   "metadata": {},
   "source": [
    "In this section we will be exploring four different model types that are known to have good applications when it comes to classification projects. These models are: Logistic Regression, Support Vector Machine, Random Forest & XGBoost. These model types will be explained in further detail as we move throughout the notebook. \n",
    "\n",
    "Each subsection (except for logistic regression) will consist of two parts: \n",
    "1. **Randomized GridSearchCV**: this enables us to cast a wider net and test a lot of hyper-parameters without being too computationally expensive. This will also be on the sample test set to speed things up further.\n",
    "2. **GridSearchCV**: Using the top results from the randomized grid search we will hone in on the best parameters for the model which produces the best hyper-parameter model using the remainder dataset.\n",
    "\n",
    "One last point to mention is the process for our pipeline that we will follow by: \n",
    "- **Vectorizing the text column**: in this project we will use the Tf-idf Vectorizer. \n",
    "- **Scaling the data**: this standardizes the data to ensure that all variables contribute equally to the model and is an important preprocessing step (especially in distance based models like Support Vector Machine).\n",
    "- **Principal Component Analysis** (where applicable): this is a technique used for reducing the dimensionality of data by identifying the most important features that explain the majority of the variability in the data. \n",
    "- **Instantiating the model**: with the chosen machine learning algorithm\n",
    "\n",
    "For our next step let's label the initial pieces like the min_df features that will apply across each models' GridSearchCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9dbcbdc4",
   "metadata": {
    "id": "9dbcbdc4"
   },
   "outputs": [],
   "source": [
    "#defining values to test for Randomized Grid Search\n",
    "vectorize_mindf_list = [0.01,0.02,0.03]\n",
    "pca_n_components = [0.95,0.90,0.85,0.80]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b1cf16",
   "metadata": {
    "id": "d4b1cf16"
   },
   "source": [
    "### <font color='256D85'> Logistic Regression <font> <a id=\"3.a\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc1b94a",
   "metadata": {},
   "source": [
    "This next section will apply logistic regression modelling to our training data. Logistic regression is a simple model, it estimates the probability of the target variable using the sigmoid function whereby it adjusts the weights of the feature inputs to try and produce the best model outcome. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1210b37f",
   "metadata": {},
   "source": [
    "#### Randomized Grid Search CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e88ac14",
   "metadata": {},
   "source": [
    "One of the hyper-parameters that we want to tune in Logistic regression is the C value which can be defined as: \n",
    "- **C**: a regularization parameter where a smaller C will result in a larger margin and a more generalized model but may lead to misclassification errors, while a larger C will result in a smaller margin but fewer misclassifications.\n",
    "\n",
    "We can define these values we want in the grid search:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "782572a0",
   "metadata": {
    "id": "782572a0"
   },
   "outputs": [],
   "source": [
    "# Range of c-values \n",
    "c_values = [.001 ,0.1, 1, 10, 100, 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886d81cc",
   "metadata": {},
   "source": [
    "The following code sets up our pipeline and parameter grid which defines our Grid Search, a method in which we can contain all of the hyper-parameters we want to test out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "273c5978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a directory to cache the pipeline results\n",
    "cachedir = mkdtemp()\n",
    "\n",
    "#estimators as a list of tuples\n",
    "pipe_log = [('transform', ct),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('dim_reducer', PCA() ),\n",
    "            ('clf', LogisticRegression(solver='lbfgs', random_state=8))]\n",
    "\n",
    "pipe = Pipeline(pipe_log,verbose=4, memory=cachedir) #setting up pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ffdb1",
   "metadata": {
    "id": "ad8ffdb1"
   },
   "outputs": [],
   "source": [
    "# Parameter grid\n",
    "log_param_grid = [\n",
    "  \n",
    "      # l2 without PCA\n",
    "    {'transform__tfidf__min_df' : vectorize_mindf_list ,\n",
    "     'transform__tfidf__max_features': [500],\n",
    "     'scaler' : ['passthrough', StandardScaler(with_mean=False),MinMaxScaler()],\n",
    "     'dim_reducer': ['passthrough'],\n",
    "     'clf': [LogisticRegression(solver='lbfgs', random_state=8, n_jobs=-1,max_iter=10000)],\n",
    "     'clf__C': c_values\n",
    "    },\n",
    "    #l2 with PCA\n",
    "     {'transform__tfidf__min_df' : vectorize_mindf_list ,\n",
    "     'transform__tfidf__max_features': [500],\n",
    "     'scaler' : ['passthrough', StandardScaler(with_mean=False),MinMaxScaler()],\n",
    "     'dim_reducer': [PCA()],\n",
    "     'dim_reducer__n_components': pca_n_components, \n",
    "     'clf': [LogisticRegression(solver='lbfgs', random_state=8, n_jobs=-1,max_iter=10000)],\n",
    "     'clf__C': c_values\n",
    "    },\n",
    "   \n",
    "     #L1 without PCA \n",
    "    {'transform__tfidf__min_df' : vectorize_mindf_list ,\n",
    "     'transform__tfidf__max_features': [500],\n",
    "     'scaler': [StandardScaler(), MinMaxScaler()], \n",
    "     'dim_reducer': ['passthrough'],\n",
    "     'clf' : [LogisticRegression(solver = 'liblinear', penalty='l1', random_state=8, n_jobs=-1,max_iter=10000)],\n",
    "     'clf__C': c_values }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0697da",
   "metadata": {},
   "source": [
    "#### A note on scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f49072",
   "metadata": {
    "id": "80f49072"
   },
   "source": [
    "For the activation of the randomized grid search we will be collecting scores in the form of f1.micro versus the default in sci-kit learn of accuracy. The reasoning behind this is that with an imbalanced data set the f1 score is a more appropriate choice since it is the harmonic mean between recall and precision, plus the f1.micro instance is better to evaluate the model on a dataset of this type. The f1-score is a measure that combines how often we're right (precision) and how often we catch all the right things (recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6YaALlyWYIY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6YaALlyWYIY",
    "outputId": "2fabcd93-f81c-4728-c699-317468faff3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   1.8s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  25.3s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=1, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.903 total time=  29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  27.7s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=1, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.900 total time=  31.4s\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   1.8s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  29.2s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=1, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=  32.9s\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  27.0s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=1, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.900 total time=  30.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  27.7s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=1, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=  31.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   1.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   1.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   1.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   1.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   1.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   3.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.2s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.904 total time=   3.6s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.6s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   3.0s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   2.8s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.6s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   2.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.6s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   2.9s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   1.0s\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   1.8s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.6s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.905 total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   1.8s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.6s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.901 total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   1.8s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.9s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.903 total time=   6.0s\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   1.8s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   5.3s\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   1.8s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.3s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   5.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.0s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.905 total time=   2.0s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.3s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   2.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.3s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.903 total time=   2.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.3s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   2.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   2.2s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.5s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.903 total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.2s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   5.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.8s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.2s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.901 total time=   5.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.6s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.903 total time=   4.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.6s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   4.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.3s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   4.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.7s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   4.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.5s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   4.3s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.7s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.903 total time=   5.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.1s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.900 total time=   5.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.7s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   5.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.3s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.900 total time=   6.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.8s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   4.7s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.7s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.7s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.7s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.7s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.7s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.6s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.905 total time=   2.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.6s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   3.0s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.8s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.903 total time=   3.1s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.900 total time=   2.6s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.7s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   3.1s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.9s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.903 total time=   3.8s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.5s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   6.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.7s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   6.6s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.3s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   5.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.9s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   5.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.905 total time=   2.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   2.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.903 total time=   2.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   2.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   2.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   3.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   3.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   3.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   3.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   3.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   2.4s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   2.4s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   2.4s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   2.4s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   2.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.907 total time=   3.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.904 total time=   3.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.907 total time=   3.9s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.904 total time=   3.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.904 total time=   3.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.5s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.904 total time=   6.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.9s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   6.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.2s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.903 total time=   7.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.9s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.901 total time=   6.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.6s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.901 total time=   6.5s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.7s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.7s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.7s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.7s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.7s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.5s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.898 total time=   4.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.7s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.896 total time=   5.1s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.3s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.898 total time=   4.7s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.6s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.895 total time=   5.1s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.6s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.895 total time=   5.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.8s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.903 total time=   5.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.2s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   4.4s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.8s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.903 total time=   5.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.1s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   5.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.7s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.901 total time=   4.8s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.0s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.903 total time=   5.9s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.1s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.900 total time=   7.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   7.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.9s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.900 total time=   6.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.9s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   8.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.7s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.904 total time=   6.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.7s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   5.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.8s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.903 total time=   5.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.2s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   7.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.7s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   6.5s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.6s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.7s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.904 total time=   3.3s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.7s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   3.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.7s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   3.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.7s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   3.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.7s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.903 total time=   3.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total= 1.4min\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=1, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.903 total time= 1.4min\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total= 1.3min\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=1, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.900 total time= 1.3min\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total= 1.2min\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=1, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time= 1.2min\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total= 1.3min\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=1, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.900 total time= 1.4min\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total= 1.5min\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=1, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time= 1.6min\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.7s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.905 total time=   2.6s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   2.0s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.3s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.903 total time=   2.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.1s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   2.0s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.5s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   2.3s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.3s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.897 total time=   2.9s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.5s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.897 total time=   3.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.3s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.898 total time=   2.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.5s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.895 total time=   3.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.5s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.897 total time=   3.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.8s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.903 total time=   2.9s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.8s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   3.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.8s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   3.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.9s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.901 total time=   3.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.8s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   3.0s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.6s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.890 total time=   2.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.6s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   2.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.6s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.890 total time=   2.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.6s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.890 total time=   2.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.6s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   2.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.1s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.894 total time=   2.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.3s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.894 total time=   2.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.896 total time=   2.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.3s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.892 total time=   2.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.2s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.893 total time=   2.8s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.5s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=1000, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.904 total time=   1.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.5s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=1000, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.899 total time=   1.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=1000, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   1.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.5s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=1000, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   1.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.4s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=1000, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   1.4s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.6s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.905 total time=   2.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.6s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   2.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.6s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.903 total time=   2.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.6s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   2.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.6s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   2.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.1s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.898 total time=   3.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.1s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.896 total time=   3.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.0s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.898 total time=   3.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.9s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.895 total time=   3.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.0s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.895 total time=   3.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.908 total time=   1.9s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.6s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.903 total time=   2.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.6s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.907 total time=   2.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.904 total time=   2.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.905 total time=   2.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.6s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.904 total time=   6.4s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.5s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   6.3s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.9s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.903 total time=   7.7s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.5s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.900 total time=   6.3s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.3s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   8.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.6s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.903 total time=   3.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.4s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.899 total time=   3.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   3.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.8s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   3.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.7s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   3.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.2s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.900 total time=   3.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.2s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.899 total time=   3.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.1s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.899 total time=   3.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.0s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.898 total time=   3.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.4s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.899 total time=   4.0s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.1s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.905 total time=   3.0s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.0s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   2.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.0s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   2.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.1s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   2.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.0s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   2.9s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.7s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=0.001, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.894 total time=   1.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.7s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=0.001, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.895 total time=   1.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.7s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=0.001, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.896 total time=   1.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.7s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=0.001, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.895 total time=   1.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 36.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   0.7s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=0.001, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.896 total time=   1.6s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.4s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.903 total time=   3.4s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.1s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   4.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.0s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   4.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.0s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   4.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.8s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   3.9s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=100, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=100, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=100, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=100, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=100, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.0s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.904 total time=   4.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.1s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.899 total time=   4.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.8s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   3.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.1s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   4.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.6s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   3.6s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.4s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.905 total time=   2.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.5s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.902 total time=   2.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.903 total time=   2.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.5s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.902 total time=   2.3s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.4s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.903 total time=   2.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.7s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.903 total time=   3.9s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.8s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.901 total time=   4.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.6s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   3.8s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.1s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   3.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.6s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.901 total time=   3.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.5s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.904 total time=   3.3s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.5s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   3.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.4s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   3.3s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.6s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   3.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.7s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.903 total time=   3.6s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=10, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=10, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=10, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=10, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=10, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.7s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.7s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.7s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.7s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.7s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.8s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.904 total time=   2.7s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.9s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.901 total time=   2.8s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.8s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.903 total time=   2.7s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.8s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.901 total time=   2.7s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.8s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   2.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.0s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.898 total time=   4.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.7s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.895 total time=   4.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.9s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.898 total time=   4.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.1s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.896 total time=   5.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.0s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=10, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.897 total time=   4.9s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.0s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.896 total time=   3.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.0s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.896 total time=   3.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.9s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.897 total time=   2.9s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.1s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.894 total time=   3.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.0s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.1, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.896 total time=   3.1s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.0s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.903 total time=   5.8s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.8s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.899 total time=   6.6s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.7s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   6.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.9s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   5.6s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.8s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.901 total time=   5.6s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.9s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.898 total time=   4.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.7s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.895 total time=   3.9s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.8s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.898 total time=   4.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.0s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.896 total time=   4.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.0s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.897 total time=   4.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   2.5s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.903 total time=   3.5s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.3s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   5.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.2s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   5.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.3s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   4.4s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   3.7s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=100, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   4.7s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=10, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=10, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=10, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=10, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', random_state=8,\n",
      "                   solver='liblinear'), clf__C=10, dim_reducer=passthrough, scaler=StandardScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.1s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   2.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.1s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   2.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.1s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   2.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.1s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   2.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.1s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   2.6s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=0.001, dim_reducer=PCA(), dim_reducer__n_components=0.85, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  10.5s\n",
      "[CV 1/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.904 total time=  11.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   8.2s\n",
      "[CV 2/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.899 total time=   9.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   9.4s\n",
      "[CV 3/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=  10.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   8.7s\n",
      "[CV 4/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   9.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.0s\n",
      "[CV 5/5] END clf=LogisticRegression(max_iter=10000, n_jobs=-1, random_state=8), clf__C=1000, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "115 fits failed out of a total of 350.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 402, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 360, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py\", line 594, in __call__\n",
      "    return self._cached_call(args, kwargs)[0]\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py\", line 537, in _cached_call\n",
      "    out, metadata = self.call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py\", line 779, in call\n",
      "    output = self.func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 894, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/decomposition/_pca.py\", line 462, in fit_transform\n",
      "    U, S, Vt = self._fit(X)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/decomposition/_pca.py\", line 480, in _fit\n",
      "    raise TypeError(\n",
      "TypeError: PCA does not support sparse input. See TruncatedSVD for a possible alternative.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "55 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 402, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 360, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py\", line 594, in __call__\n",
      "    return self._cached_call(args, kwargs)[0]\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py\", line 537, in _cached_call\n",
      "    out, metadata = self.call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py\", line 779, in call\n",
      "    output = self.func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 894, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py\", line 851, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py\", line 427, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py\", line 460, in partial_fit\n",
      "    raise TypeError(\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 402, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 360, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py\", line 594, in __call__\n",
      "    return self._cached_call(args, kwargs)[0]\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py\", line 537, in _cached_call\n",
      "    out, metadata = self.call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py\", line 779, in call\n",
      "    output = self.func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 894, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py\", line 851, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py\", line 824, in fit\n",
      "    return self.partial_fit(X, y, sample_weight)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py\", line 889, in partial_fit\n",
      "    raise ValueError(\n",
      "ValueError: Cannot center sparse matrices: pass `with_mean=False` instead. See docstring for motivation and alternatives.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.90135631        nan 0.90201243        nan        nan        nan\n",
      " 0.90223796 0.90260704        nan 0.90128455 0.90135631 0.9013153\n",
      "        nan        nan 0.90223796 0.90176639 0.90306837 0.88857222\n",
      " 0.88857222 0.90511875 0.90143833        nan        nan        nan\n",
      " 0.89628161 0.90135631        nan 0.90132556 0.90164336        nan\n",
      " 0.90217647 0.90130505 0.90261729 0.89663019 0.90166387 0.88979219\n",
      " 0.89387242        nan 0.90117177 0.90309913 0.89627136 0.90534429\n",
      " 0.90194067 0.90115127 0.89905989 0.90204319 0.89508217 0.90190991\n",
      "        nan 0.90118202 0.90298636 0.90127429 0.90230974        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.90208419 0.89673271 0.89583054 0.90114102 0.89660969 0.90175613\n",
      "        nan 0.88857222        nan 0.90115127]\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.7s\n"
     ]
    }
   ],
   "source": [
    "#logistic grid search set up \n",
    "log_gs = RandomizedSearchCV(estimator = pipe, \n",
    "                           param_distributions= log_param_grid, \n",
    "                           cv=5, \n",
    "                           n_jobs = 1,\n",
    "                           n_iter = 70,\n",
    "                           verbose = 3,\n",
    "                           refit=True,\n",
    "                           scoring = 'f1_micro', \n",
    "                           random_state = 8)\n",
    "\n",
    "fitted_log_gs = log_gs.fit(X_remainder1, y_remainder1)\n",
    "\n",
    "grid_search_results = fitted_log_gs.cv_results_\n",
    "\n",
    "best_estimator = fitted_log_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cc4d2d",
   "metadata": {},
   "source": [
    "After running through the initial hyper-parameter options, we can now select the best results. The function below saves the output from the Randomized GridSearchCV, but is only relevant if you want to save to a AWS S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3becdbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results_to_s3(grid_search_results, filename, bucket, key):\n",
    "    \"\"\"\n",
    "    This function writes a DataFrame of grid search results to a CSV file and uploads it to an S3 bucket.\n",
    "    \n",
    "    Inputs: \n",
    "    - tfidf_results: A DataFrame of grid search results.\n",
    "    - filename: The name of the CSV file to write the results to.\n",
    "    - bucket: The name of the S3 bucket to upload the file to.\n",
    "    - key: The S3 key to use for the uploaded file\n",
    "    \"\"\"\n",
    "    # Write the results to a CSV file\n",
    "    results = pd.DataFrame(grid_search_results)\n",
    "    results.to_csv(filename, index=False)\n",
    "\n",
    "    # Upload the file to S3\n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_client.upload_file(Filename=filename, Bucket=bucket, Key=key)\n",
    "\n",
    "    print(f\"{filename} has been saved to {bucket}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jJEiTzVpYAoh",
   "metadata": {
    "id": "jJEiTzVpYAoh"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#saving results to s3 bucket\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m write_results_to_s3(\u001b[43mgrid_search_results\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_results_model_1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeliverable-slo-bstn-bucket\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_results_model_1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_search_results' is not defined"
     ]
    }
   ],
   "source": [
    "#saving results to s3 bucket\n",
    "write_results_to_s3(grid_search_results, 'log_results_model_1.csv', 'deliverable-slo-bstn-bucket', 'log_results_model_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f1e064",
   "metadata": {},
   "source": [
    "Since we put the entire remainder dataset into the model we can save the best model from this search as our best estimator. We created another function for this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5642f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_model(best_estimator, filename, bucket='deliverable-slo-bstn-bucket', key=None):\n",
    "    \"\"\"\n",
    "    This function saves the best estimator from a grid search to a joblib file and upload it to an S3 bucket.\n",
    "\n",
    "    Inputs: \n",
    "    - best_estimator: The best estimator from grid search.\n",
    "    - filename: The name of the file to save the best estimator to.\n",
    "    - bucket : The name of the S3 bucket to upload the file to (if provided).\n",
    "    - key: The S3 key to use for the uploaded file (if provided).\n",
    "    \"\"\"\n",
    "    joblib.dump(best_estimator, filename)\n",
    "\n",
    "    if bucket is not None and key is not None:\n",
    "        s3_client = boto3.client('s3')\n",
    "        s3_client.upload_file(Filename=filename, Bucket=bucket, Key=key)\n",
    "\n",
    "    print(f\"{filename} has been saved to {bucket}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qtbu3g2fEwUG",
   "metadata": {
    "id": "qtbu3g2fEwUG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickled_best_log_reg1.pkl has been saved to deliverable-slo-bstn-bucket\n"
     ]
    }
   ],
   "source": [
    "# saving logreg pickle file\n",
    "save_best_model(best_estimator, 'pickled_best_log_reg1.pkl', bucket='deliverable-slo-bstn-bucket', key='pickled_best_log_reg1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36488fd2",
   "metadata": {},
   "source": [
    "We have the best hyper-parameters and can access them through a pickle file but we need to output the F1-score against our train and validation datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e03501f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e03501f",
    "outputId": "fbb52000-f02d-4f15-c499-b65d7be6f8bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best logistic regression's accuracy on the remainder set: 0.9065642844694135\n",
      "The best logistic regression's accuracy on the test set: 0.9067097237172587\n"
     ]
    }
   ],
   "source": [
    "# Sanity check on the pickled model\n",
    "filename ='pickled_best_log_reg1.pkl'\n",
    "pickled_best_logreg = joblib.load(filename)\n",
    "\n",
    "# Print the accuracies\n",
    "print(f\"The best logistic regression's f1.micro score on the train set: {pickled_best_logreg.score(X_train1, y_train1)}\")\n",
    "print(f\"The best logistic regression's f1.micro score on the validation set: {pickled_best_logreg.score(X_val1, y_val1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade39e6e",
   "metadata": {},
   "source": [
    "Is 90.6% a good score? We can measure this against our baseline which is the proportional split in our target data which we defined in the train/test split section as being 88.85%. Therefore, we did improve our score by 2% with logistic regression. Let's summarize this and our logistic model results in a table and move on to model Support Vector Machine. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af40efc0",
   "metadata": {},
   "source": [
    "| **Model**           | **F1-Micro Score** | **Best Parameters TFIDF**         | **Best Parameters Scaler/PCA** | **Best Parameters Model**         | **Method**         |\n",
    "|---------------------|---------------------|-----------------------------------|--------------------------------|-----------------------------------|--------------------|\n",
    "| Logistic Regression | 90.67%              | [min_df=0.01, max_features = 500] | [StandardScaler, no PCA]       | [lbfgs, penalty = L2, C = 0.001]  | RandomizedSearchCV |\n",
    "| Baseline            | 88.85%              | ------------------               | ------------------           | -----------------------         | For comparison     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e51a82",
   "metadata": {
    "id": "96e51a82"
   },
   "source": [
    "### <font color='256D85'> Support Vector Machine <font> <a id=\"3.b\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a0911",
   "metadata": {},
   "source": [
    "In this section we will be exploring the support vector machine (SVM) modelling method. In short, the method tries to find the best line or curve (named the decision boundary) that separates, in this case, two groups in the best possible way.  SVM is a distance-based modelling method which tries to maximize the distance between the two groups of data points to make the most accurate predictions possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af385ff1",
   "metadata": {},
   "source": [
    "#### Randomized GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08e255f",
   "metadata": {
    "id": "c08e255f"
   },
   "source": [
    "Let's set our specific hyper-parameters for SVM of which there are two main hyper-parameters we will define: \n",
    "- **C**: Like Logistic Regression C is a regularization parameter where a smaller C will result in a larger margin and a more generalized model but may lead to misclassification errors, while a larger C will result in a smaller margin but fewer misclassifications.\n",
    "- **Gamma**: Controls the decision boundary, where if gamma is small the decision boundary is smoother, but if it is larger, then the decision boundary is more complex. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd45abb2",
   "metadata": {
    "id": "fd45abb2"
   },
   "outputs": [],
   "source": [
    "#hyper parameters SVM\n",
    "param_range =[0.1,1,10]\n",
    "gamma_range = [0.1,0.01]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439547bf",
   "metadata": {},
   "source": [
    "Since SVM is distance-based modelling method applying a scaler is crucial here for the validity of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce05066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a directory to cache the pipeline results\n",
    "cachedir = mkdtemp()\n",
    "\n",
    "#pipeline steps according to tranform, pca, scale, \n",
    "pipe_svm = [('transform', ct),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('dim_reducer', PCA()),\n",
    "            ('clf', SVC(random_state=8))]\n",
    "\n",
    "pipe = Pipeline(pipe_svm,verbose=4, memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c455c0ab",
   "metadata": {
    "id": "c455c0ab"
   },
   "outputs": [],
   "source": [
    "# Parameter grid\n",
    "svm_param_grid = [\n",
    "    # SVM  without PCA\n",
    "    {'transform__tfidf__min_df' : vectorize_mindf_list ,\n",
    "     'transform__tfidf__max_features': [500],\n",
    "     'scaler' : ['passthrough', StandardScaler(with_mean=False), MinMaxScaler()],\n",
    "     'dim_reducer': ['passthrough'],\n",
    "     'clf' : [SVC(random_state=8)],\n",
    "     'clf__kernel': ['rbf','sigmoid'],\n",
    "     'clf__C': param_range,\n",
    "     'clf__gamma':gamma_range\n",
    "     },\n",
    "     \n",
    "     #SVM with PCA\n",
    "     {'transform__tfidf__min_df' : vectorize_mindf_list ,\n",
    "     'transform__tfidf__max_features': [500],\n",
    "     'scaler' : [StandardScaler(with_mean=False), MinMaxScaler()],\n",
    "     'dim_reducer': [PCA()],\n",
    "     'dim_reducer__n_components':[0.95 ,0.9 ,0.8],\n",
    "      'clf' : [SVC(random_state=8)], \n",
    "     'clf__kernel': ['rbf','sigmoid'],\n",
    "     'clf__C': param_range,\n",
    "     'clf__gamma':gamma_range\n",
    "     }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a249060",
   "metadata": {},
   "source": [
    "Now that the pipeline and param grid have been set up let's run the RandomizedSearchCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XQXGrHYAWuN5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQXGrHYAWuN5",
    "outputId": "59336935-1513-413a-f36a-19de195ae614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   0.4s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  14.9s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.913 total time=  18.6s\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   0.4s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  15.2s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.917 total time=  18.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   0.4s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  14.7s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.915 total time=  18.4s\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   0.4s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  15.0s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.913 total time=  18.7s\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   0.4s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  14.3s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.907 total time=  18.0s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.2s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  11.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.886 total time=  13.3s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.885 total time=  13.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  11.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.885 total time=  13.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  10.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.886 total time=  13.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  10.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.885 total time=  12.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.1s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   0.3s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.9s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.4s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.9s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.3s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.888 total time=   8.1s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.4s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.890 total time=   8.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.0s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.887 total time=   7.3s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.2s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.891 total time=   7.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.5s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.886 total time=   7.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.3s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.888 total time=   7.6s\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.2s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.8s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   6.6s\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.4s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.0s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.5s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.888 total time=   7.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.0s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   7.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.9s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   9.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.7s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   6.8s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.4s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=   8.5s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.7s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=   6.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.3s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=   9.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.905 total time=   8.9s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.0s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.901 total time=   8.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.0s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.903 total time=   8.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.0s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.899 total time=   8.8s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   9.4s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.911 total time=  12.0s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   9.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.915 total time=  11.8s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   9.5s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.914 total time=  12.0s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   9.2s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.913 total time=  11.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   8.8s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.907 total time=  11.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   8.9s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=  11.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   8.4s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=  11.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   8.5s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=  11.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   8.4s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=  11.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   8.5s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.888 total time=  11.2s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.0s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   7.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.0s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   7.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.0s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   7.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.8s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   7.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.8s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.888 total time=   7.3s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.3s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.923 total time=   7.7s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.4s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.927 total time=   7.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.3s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.925 total time=   7.7s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.3s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.921 total time=   7.8s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.3s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.918 total time=   7.8s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.5s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.841 total time=   9.1s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   9.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.832 total time=  10.6s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.7s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.830 total time=   8.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.5s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.832 total time=   8.0s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.4s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.830 total time=   7.9s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.9s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.904 total time=   8.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.0s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.906 total time=   8.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.9s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.903 total time=   8.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.9s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.905 total time=   8.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   8.8s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.8s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   7.9s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.3s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   8.5s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.6s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   7.7s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.6s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   8.7s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.3s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.898 total time=   7.4s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.2s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   8.1s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.3s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   8.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.3s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   8.3s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.3s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   8.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.3s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   8.3s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  52.2s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.905 total time=  57.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  47.9s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.909 total time=  53.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  48.1s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.910 total time=  53.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total= 1.1min\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.907 total time= 1.2min\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  58.4s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time= 1.1min\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.0s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   7.6s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.9s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   7.4s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.2s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.893 total time=   7.7s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.2s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   7.7s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.4s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.897 total time=   7.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   8.1s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.911 total time=   9.6s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   8.0s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.915 total time=   9.6s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   8.0s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.914 total time=   9.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   8.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.913 total time=   9.7s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.6s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.907 total time=   8.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.8s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   8.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.8s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   8.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.6s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   8.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   8.3s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   9.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.6s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.888 total time=   7.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  40.7s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=  45.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  38.6s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.906 total time=  43.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  38.8s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=  43.3s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  49.8s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.907 total time=  54.3s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  39.0s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=  43.3s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.3s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.904 total time=   6.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.3s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.906 total time=   6.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.4s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.903 total time=   6.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.3s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.905 total time=   6.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.2s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   6.5s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  10.6s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.926 total time=  13.8s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  10.6s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.931 total time=  14.0s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  10.6s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.929 total time=  13.7s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  10.7s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.929 total time=  14.0s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  10.6s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.925 total time=  13.8s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.4s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.876 total time=   6.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.875 total time=   7.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.2s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.869 total time=   7.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.871 total time=   6.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.0s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.864 total time=   6.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.4s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.898 total time=   9.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.3s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.898 total time=   9.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.2s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   9.3s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.4s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.897 total time=   9.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   8.6s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.897 total time=  10.8s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  15.5s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=  19.7s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  14.8s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=  18.9s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  14.6s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.889 total time=  18.9s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  15.0s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.890 total time=  19.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  14.0s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.890 total time=  18.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  53.1s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.892 total time=  57.5s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  50.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=  54.6s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  50.0s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.888 total time=  54.6s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  50.4s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.891 total time=  55.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  50.4s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.890 total time=  54.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.4s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.841 total time=   8.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.5s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.848 total time=   7.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.3s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.853 total time=   8.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.7s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.843 total time=   9.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.6s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.845 total time=   8.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  10.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.848 total time=  12.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  10.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.851 total time=  12.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  10.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.844 total time=  12.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  10.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.847 total time=  12.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1008: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  inplace_column_scale(X, 1 / self.scale_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.842 total time=  12.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.7s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.843 total time=   7.8s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.7s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.834 total time=   7.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.8s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.825 total time=   7.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.8s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.830 total time=   8.0s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.7s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.834 total time=   7.8s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.9s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.830 total time=   7.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.8s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.821 total time=   7.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.4s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.814 total time=   6.6s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.8s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.817 total time=   7.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.3s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.822 total time=   6.5s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  49.4s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.901 total time=  54.4s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  44.6s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.907 total time=  49.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  44.7s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.905 total time=  49.5s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  44.8s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.905 total time=  49.5s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  48.8s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.900 total time=  53.7s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=nan total time=   0.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.5s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.901 total time=   8.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.5s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.905 total time=   7.9s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.5s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.900 total time=   8.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.4s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.903 total time=   7.9s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.6s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.899 total time=   8.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  29.4s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.903 total time=  32.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  28.6s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.906 total time=  31.5s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  29.5s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.906 total time=  32.5s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  30.0s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.905 total time=  32.8s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  29.8s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.902 total time=  32.6s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  46.2s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.895 total time=  51.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  45.5s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.890 total time=  50.7s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  45.6s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.894 total time=  50.4s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  45.2s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.893 total time=  50.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  47.3s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.893 total time=  52.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.7s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.919 total time=   8.4s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.6s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.918 total time=   8.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.6s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.916 total time=   8.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.6s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.915 total time=   8.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.6s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.911 total time=   8.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  50.9s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.892 total time=  56.6s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  49.6s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.891 total time=  55.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  50.9s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.891 total time=  56.7s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  53.6s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.892 total time=  59.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  52.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.892 total time=  58.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.1s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.885 total time=   7.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.3s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.886 total time=   7.4s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.4s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.887 total time=   7.5s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.3s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.887 total time=   7.5s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.0s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=0.1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.886 total time=   6.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.9s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   9.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.8s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   8.9s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.7s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.902 total time=   8.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.8s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.889 total time=   8.9s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   7.3s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.898 total time=   8.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  18.0s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.945 total time=  20.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  18.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.948 total time=  20.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  17.3s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.950 total time=  20.1s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  18.0s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.948 total time=  20.9s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  18.2s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=passthrough, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.943 total time=  21.1s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  10.8s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.920 total time=  13.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   9.5s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.919 total time=  12.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   9.7s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.920 total time=  12.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   9.7s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.919 total time=  12.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   9.8s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=passthrough, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.914 total time=  12.7s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.3s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.872 total time=   6.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.1s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.871 total time=   7.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.9s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.876 total time=   6.8s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   5.6s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.865 total time=   6.6s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   6.1s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.871 total time=   7.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.4s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.827 total time=   5.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.3s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.825 total time=   5.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.5s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.821 total time=   5.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.3s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.823 total time=   5.5s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=   4.3s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=1, clf__gamma=0.01, clf__kernel=sigmoid, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=StandardScaler(with_mean=False), transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.826 total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "90 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 402, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 360, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py\", line 594, in __call__\n",
      "    return self._cached_call(args, kwargs)[0]\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py\", line 537, in _cached_call\n",
      "    out, metadata = self.call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py\", line 779, in call\n",
      "    output = self.func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 894, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py\", line 851, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py\", line 427, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py\", line 460, in partial_fit\n",
      "    raise TypeError(\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 402, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 360, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py\", line 594, in __call__\n",
      "    return self._cached_call(args, kwargs)[0]\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py\", line 537, in _cached_call\n",
      "    out, metadata = self.call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py\", line 779, in call\n",
      "    output = self.func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 894, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/decomposition/_pca.py\", line 462, in fit_transform\n",
      "    U, S, Vt = self._fit(X)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/decomposition/_pca.py\", line 480, in _fit\n",
      "    raise TypeError(\n",
      "TypeError: PCA does not support sparse input. See TruncatedSVD for a possible alternative.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.9133173         nan        nan        nan        nan        nan\n",
      " 0.88553414 0.88855855        nan 0.88850713 0.88855855 0.89091692\n",
      " 0.90183506        nan 0.91198461 0.88855855        nan        nan\n",
      " 0.88855855 0.92269804 0.83299138 0.90388549 0.8904555  0.88866108\n",
      "        nan 0.906756   0.89112178 0.91193334 0.88855855 0.90337295\n",
      "        nan 0.90388548        nan 0.92787563        nan        nan\n",
      " 0.87087311 0.89799046        nan 0.88922496 0.88999389 0.84601167\n",
      " 0.84637052 0.83329902        nan        nan 0.82074009 0.90373169\n",
      "        nan 0.9016813  0.90444933 0.89306949 0.91588041 0.89142918\n",
      " 0.88609805 0.8931208  0.94694474 0.91808471 0.8708732  0.82432849]\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   0.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  46.9s\n"
     ]
    }
   ],
   "source": [
    "#activating randomized grid search \n",
    "svm_random = RandomizedSearchCV(estimator = pipe, \n",
    "                           param_distributions= svm_param_grid, \n",
    "                           cv=5, \n",
    "                           n_iter = 60,\n",
    "                           verbose = 4,\n",
    "                           refit=True,\n",
    "                           scoring = 'f1_micro', \n",
    "                           random_state = 8)\n",
    "\n",
    "fitted_svmrandom_gs = svm_random.fit(X_remainder1_sample, y_remainder1_sample)\n",
    "\n",
    "grid_search_results = fitted_svmrandom_gs.cv_results_\n",
    "\n",
    "best_estimator = fitted_svmrandom_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffbe788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_results_random_model1.csv has been saved to deliverable-slo-bstn-bucket\n"
     ]
    }
   ],
   "source": [
    "# saving results to s3 bucket\n",
    "write_results_to_s3(grid_search_results, 'svm_results_random_model1.csv', 'deliverable-slo-bstn-bucket', 'svm_results_random_model1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b51af76",
   "metadata": {},
   "source": [
    "#### Refined Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39517fa7",
   "metadata": {},
   "source": [
    "Let's apply the learnings from the prior section and go through our pipeline, parameter grid and activation process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaf197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a directory to cache the pipeline results\n",
    "cachedir = mkdtemp()\n",
    "\n",
    "#pipeline steps according to tranform, pca, scale, \n",
    "pipe_svm = [('transform', ct),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('dim_reducer', PCA()),\n",
    "            ('clf', SVC(random_state=8))]\n",
    "\n",
    "pipe = Pipeline(pipe_svm,verbose=4, memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c9646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#more refined parameters\n",
    "# Parameter grid\n",
    "svm_param_grid2 = [ \n",
    "      \n",
    "    # SVM with PCA\n",
    "    {'transform__tfidf__min_df' : [0.02,0.025],\n",
    "     'transform__tfidf__max_features': [1000],\n",
    "     'scaler' : [MinMaxScaler()],\n",
    "     'dim_reducer': [PCA()],\n",
    "     'dim_reducer__n_components':[0.95 ,0.9 ,0.8],\n",
    "     'clf' : [SVC(random_state=8)],\n",
    "     'clf__kernel': ['rbf'],\n",
    "     'clf__C': [10],\n",
    "     'clf__gamma':[0.1]\n",
    "     }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e86aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.66s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.60s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.65s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.60s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.63s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.62s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.65s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.65s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.70s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.68s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.63s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.65s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.68s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.91s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.73s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.69s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.72s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.73s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.93s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.68s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.68s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.92s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.94s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 1.02s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 0.75s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 1.18s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 1.22s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 1.22s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 1.29s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:360: UserWarning: Persisting input arguments took 1.18s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  X, fitted_transformer = fit_transform_one_cached(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.7s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.015;, score=nan total time=   5.7s\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.7s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.015;, score=nan total time=   5.7s\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   4.4s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.015;, score=nan total time=   6.1s\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   4.1s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.015;, score=nan total time=   6.6s\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.9s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.015;, score=nan total time=   6.6s\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   4.9s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.015;, score=nan total time=   7.5s\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.7s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.015;, score=nan total time=   5.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   2.6s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=14.1min\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.914 total time=14.9min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   2.8s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.015;, score=nan total time=   4.4s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   4.8s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=14.7min\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.919 total time=15.6min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   2.4s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.015;, score=nan total time=   4.0s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   3.2s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=15.1min\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.918 total time=15.7min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   2.6s\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.015;, score=nan total time=   4.1s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   4.8s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=12.7min\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.916 total time=13.7min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.6s\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.015;, score=nan total time=   5.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   3.6s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=14.1min\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.915 total time=15.1min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.4s\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.015;, score=nan total time=   5.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   3.6s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=14.4min\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.915 total time=15.0min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.3s\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.015;, score=nan total time=   5.0s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   3.4s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=14.5min\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.917 total time=15.4min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.6s\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.015;, score=nan total time=   5.6s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   3.6s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=15.1min\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.916 total time=15.8min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.7s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   3.4s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=15.5min\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.920 total time=16.3min\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.015;, score=nan total time=   0.8s\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.8s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   3.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=15.6min\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.8, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.919 total time=16.3min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.3s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   2.9s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=17.0min\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.920 total time=17.9min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   2.8s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=17.3min\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.919 total time=18.1min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   2.6s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=17.6min\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.921 total time=18.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 402, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 360, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py\", line 594, in __call__\n",
      "    return self._cached_call(args, kwargs)[0]\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py\", line 537, in _cached_call\n",
      "    out, metadata = self.call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/memory.py\", line 779, in call\n",
      "    output = self.func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 894, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py\", line 851, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py\", line 427, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py\", line 460, in partial_fit\n",
      "    raise TypeError(\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.92303905 0.92108095        nan 0.92204463 0.92070163\n",
      "        nan 0.91841546 0.91521687]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.scale_ = (feature_range[1] - feature_range[0]) / _handle_zeros_in_scale(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   0.4s\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   2.9s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=19.1min\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.919 total time=20.0min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.1s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   3.6s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=19.1min\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.921 total time=20.0min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.3s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   4.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=19.1min\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.921 total time=20.0min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   3.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=19.2min\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.922 total time=20.1min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   4.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=19.3min\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.924 total time=20.2min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   4.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=19.3min\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.920 total time=20.3min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   4.9s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=19.4min\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.922 total time=20.3min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.3s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   3.7s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=19.9min\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.922 total time=20.7min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   2.7s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=20.0min\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.921 total time=20.8min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.2s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   2.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=20.3min\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.922 total time=21.1min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.4s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   4.1s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=20.6min\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.9, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.923 total time=21.4min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   2.6s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   2.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=20.8min\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.923 total time=21.5min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.4s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   4.3s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=22.6min\n",
      "[CV 1/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.925 total time=23.6min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   2.5s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   3.7s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=22.6min\n",
      "[CV 3/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.923 total time=23.6min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.3s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   3.7s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=22.8min\n",
      "[CV 4/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.920 total time=23.8min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   2.8s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   3.4s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=23.0min\n",
      "[CV 5/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.924 total time=23.9min\n",
      "[Pipeline] ......... (step 1 of 4) Processing transform, total=   3.3s\n",
      "[Pipeline] ............ (step 2 of 4) Processing scaler, total=   0.2s\n",
      "[Pipeline] ....... (step 3 of 4) Processing dim_reducer, total=   4.9s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=23.1min\n",
      "[CV 2/5] END clf=SVC(random_state=8), clf__C=10, clf__gamma=0.1, clf__kernel=rbf, dim_reducer=PCA(), dim_reducer__n_components=0.95, scaler=MinMaxScaler(), transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.923 total time=24.2min\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=19.6min\n",
      "Pipeline(memory='/tmp/tmphyteer08',\n",
      "         steps=[('transform',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('tfidf',\n",
      "                                                  TfidfVectorizer(max_features=1000,\n",
      "                                                                  min_df=0.02,\n",
      "                                                                  stop_words='english'),\n",
      "                                                  'reviewText'),\n",
      "                                                 ('scale', StandardScaler(),\n",
      "                                                  Index(['overall', 'vote', 'verified', 'price_USD', 'ranking',\n",
      "       'also_buy_counts', 'also_view_counts', 'c_accessories',\n",
      "       'c_bath and sh...\n",
      "       'm_Laura Geller', 'm_Mario Badescu', 'm_Mustela', 'm_NUXE',\n",
      "       'm_Natura Bisse', 'm_OPI', 'm_Oribe', 'm_Other', 'm_PCA Skin',\n",
      "       'm_Paul Mitchell', 'm_Pureology', 'm_RUSK', 'm_Red Flower',\n",
      "       'm_Rene Furterer', 'm_Stila', 'm_StriVectin', 'm_TS',\n",
      "       'm_The Art of Shaving', 'm_Vichy', 'm_theBalm'],\n",
      "      dtype='object'))])),\n",
      "                ('scaler', MinMaxScaler()),\n",
      "                ('dim_reducer', PCA(n_components=0.95)),\n",
      "                ('clf', SVC(C=10, gamma=0.1, random_state=8))],\n",
      "         verbose=4)\n"
     ]
    }
   ],
   "source": [
    "#more refined grid search\n",
    "svm_gs = GridSearchCV(estimator = pipe, \n",
    "                           param_grid= svm_param_grid2, \n",
    "                           cv=5, \n",
    "                           verbose = 4,\n",
    "                           n_jobs=-1,\n",
    "                           refit=True,\n",
    "                           scoring = 'f1_micro')\n",
    "\n",
    "fitted_svm_gs = svm_gs.fit(X_remainder1, y_remainder1)\n",
    "\n",
    "grid_search_results = fitted_svm_gs.cv_results_\n",
    "\n",
    "best_estimator = fitted_svm_gs.best_estimator_\n",
    "print(best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7CYuELHSxL",
   "metadata": {
    "id": "0e7CYuELHSxL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickled_best_svm_model1.pkl has been saved to deliverable-slo-bstn-bucket\n"
     ]
    }
   ],
   "source": [
    "# saving svmreg pickle file\n",
    "save_best_model(best_estimator, 'pickled_best_svm_model1.pkl', bucket='deliverable-slo-bstn-bucket', key='pickled_best_svm_model1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f71e3f3",
   "metadata": {},
   "source": [
    "Showing our best model parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c59c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='/tmp/tmphyteer08',\n",
      "         steps=[('transform',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('tfidf',\n",
      "                                                  TfidfVectorizer(max_features=1000,\n",
      "                                                                  min_df=0.02,\n",
      "                                                                  stop_words='english'),\n",
      "                                                  'reviewText'),\n",
      "                                                 ('scale', StandardScaler(),\n",
      "                                                  Index(['overall', 'vote', 'verified', 'price_USD', 'ranking',\n",
      "       'also_buy_counts', 'also_view_counts', 'c_accessories',\n",
      "       'c_bath and sh...\n",
      "       'm_Laura Geller', 'm_Mario Badescu', 'm_Mustela', 'm_NUXE',\n",
      "       'm_Natura Bisse', 'm_OPI', 'm_Oribe', 'm_Other', 'm_PCA Skin',\n",
      "       'm_Paul Mitchell', 'm_Pureology', 'm_RUSK', 'm_Red Flower',\n",
      "       'm_Rene Furterer', 'm_Stila', 'm_StriVectin', 'm_TS',\n",
      "       'm_The Art of Shaving', 'm_Vichy', 'm_theBalm'],\n",
      "      dtype='object'))])),\n",
      "                ('scaler', MinMaxScaler()),\n",
      "                ('dim_reducer', PCA(n_components=0.95)),\n",
      "                ('clf', SVC(C=10, gamma=0.1, random_state=8))],\n",
      "         verbose=4)\n"
     ]
    }
   ],
   "source": [
    "#best estimator\n",
    "print(fitted_svm_gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ec6a47",
   "metadata": {
    "id": "10ec6a47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best SVM f1-micro score on the remainder set: 0.9270064440538958\n",
      "The best SVM f1-micro score on the test set: 0.9267334176263541\n"
     ]
    }
   ],
   "source": [
    "# Sanity check on the pickled model\n",
    "pklfilename = 'pickled_best_svm_model1.pkl'\n",
    "\n",
    "pickled_best_svm1 = joblib.load(pklfilename)\n",
    "\n",
    "# Print the accuracies\n",
    "print(f\"The best SVM f1-micro score on the remainder set: {pickled_best_svm1.score(X_train1, y_train1)}\")\n",
    "print(f\"The best SVM f1-micro score on the test set: {pickled_best_svm1.score(X_val1, y_val1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35901249",
   "metadata": {},
   "source": [
    "This is an improvement over logistic regression, but it took significantly longer to run so if we had a larger data set to work with that may be an issue in the future. Let's summarize these results in our table and move onto Random Forest Modelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568e4c30",
   "metadata": {},
   "source": [
    "| **Model**              | **F1-Micro Score** | **Best Parameters TFIDF**          | **Best Parameters Scaler/PCA** | **Best Parameters Model**         | **Method**         |\n",
    "|------------------------|---------------------|------------------------------------|--------------------------------|-----------------------------------|--------------------|\n",
    "| Logistic Regression    | 90.67%              | [min_df=0.01, max_features = 500]  | [StandardScaler, no PCA]       | [lbfgs, penalty = L2, C = 0.001]  | RandomizedSearchCV |\n",
    "| Support Vector Machine | 91.56%              | [min_df=0.02, max_features = 500]  | [MinMaxScaler, PCA(0.9)]       | [rbf, gamma = 0.1, C = 10]        | RandomizedSearchCV |\n",
    "| Support Vector Machine | 92.67%              | [min_df=0.02, max_features = 1000] | [MinMaxScaler, PCA(0.95)]      | [rbf, gamma = 0.1, C = 10]        | GridSearchCV       |\n",
    "| Baseline               | 88.85%              | -------------------                | -------------------            | -----------------------         | For comparison     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa2b308",
   "metadata": {
    "id": "dfa2b308"
   },
   "source": [
    "### <font color='256D85'> Random Forest Modelling <font> <a id=\"3.c\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3200a282",
   "metadata": {},
   "source": [
    "For our third modelling technique we will apply Random Forest modelling, a machine learning algorithm that uses multiple decision trees to make predictions. Each decision tree using our data set will be built on a different subset of the data and features in order to test out as many variations of the data as possible and in doing so, avoids overfitting and provides better generalization to any new data that might follow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a77a87",
   "metadata": {},
   "source": [
    "#### Randomized GridSearchCV on Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a0fd41",
   "metadata": {},
   "source": [
    "In this subsection we will define our hyper-parameters for the Randomized GridSearchCV. Those specific to Random Forest are: \n",
    "\n",
    "- **n_estimators**: The number of trees in the model, increasing the number of trees generally improves performance but may lead to overfitting. \n",
    "- **max_depth_range**: indicates the depth of the tree, increasing it increases the model complexity. \n",
    "- **max_features_range**: This determines the max number of features the model is allowed to consider when looking for the best split.  \n",
    "\n",
    "Note: scaling and dimension reducing is not required in this model since  it is a tree-based model and can select the most important features for the split at each node of the tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c120af2",
   "metadata": {
    "id": "3c120af2"
   },
   "outputs": [],
   "source": [
    "#hyper parameters Random Forest \n",
    "n_estimators_range = list(range(100,1600,200))\n",
    "max_depth_range = list(range(10,50,10))\n",
    "max_features_range = np.arange(0.2,0.6,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3707f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a directory to cache the pipeline results\n",
    "cachedir = mkdtemp()\n",
    "\n",
    "#pipeline steps according to tranform, pca, scale, \n",
    "pipe_rf = [('transform', ct),\n",
    "           ('clf', RandomForestClassifier(n_jobs = 1))]\n",
    "\n",
    "pipe = Pipeline(pipe_rf,verbose=4, memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f613f0",
   "metadata": {
    "id": "97f613f0"
   },
   "outputs": [],
   "source": [
    "# Parameter grid\n",
    "rf_param_grid = [\n",
    "    # Random Forest without PCA\n",
    "    {'transform__tfidf__min_df' : vectorize_mindf_list ,\n",
    "     'transform__tfidf__max_features': [500],\n",
    "     'clf': [RandomForestClassifier(n_jobs = 1)],\n",
    "     'clf__max_depth': max_depth_range,\n",
    "     'clf__n_estimators':n_estimators_range,\n",
    "     'clf__max_features' :max_features_range\n",
    "     }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c22501",
   "metadata": {
    "id": "e3c22501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.4s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.952 total time=  13.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.4s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.948 total time=  13.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.7s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.953 total time=  13.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.8s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.948 total time=  13.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  12.7s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.944 total time=  13.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  15.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.936 total time=  16.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  15.2s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.936 total time=  16.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  15.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.935 total time=  16.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  15.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.935 total time=  16.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  15.6s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.930 total time=  16.5s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.9s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.934 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.9s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.933 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.9s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.928 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.9s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.933 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.9s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.925 total time=   3.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  52.6s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=900, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.934 total time=  53.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  52.9s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=900, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.932 total time=  53.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  52.9s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=900, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.932 total time=  53.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  53.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=900, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.931 total time=  53.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  53.3s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=900, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.924 total time=  54.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  16.3s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.962 total time=  16.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  16.2s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.966 total time=  16.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  16.4s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.960 total time=  16.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  16.3s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.958 total time=  16.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  16.8s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.959 total time=  17.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  51.6s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.958 total time=  52.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  49.8s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.961 total time=  50.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  50.4s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.956 total time=  51.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  50.3s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.954 total time=  51.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  50.6s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.951 total time=  51.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.0min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.972 total time= 1.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  58.7s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.973 total time=  59.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  59.9s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.970 total time= 1.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  58.7s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.969 total time=  59.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  59.2s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.967 total time=  60.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  41.2s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.978 total time=  41.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  39.2s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.977 total time=  39.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  40.0s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.976 total time=  40.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  39.7s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.977 total time=  40.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  39.5s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.974 total time=  40.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.8s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.936 total time=  24.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.8s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.938 total time=  24.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.8s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.934 total time=  24.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.8s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.935 total time=  24.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  24.6s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.928 total time=  25.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  17.6s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.935 total time=  18.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  17.8s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.931 total time=  18.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  18.0s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.931 total time=  18.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  17.8s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.932 total time=  18.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  17.7s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.924 total time=  18.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.0s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.963 total time=  23.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  22.9s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.963 total time=  23.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  22.8s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.960 total time=  23.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  22.7s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.960 total time=  23.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.4s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.958 total time=  23.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 5.3min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.964 total time= 5.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 5.3min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.964 total time= 5.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 5.2min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.965 total time= 5.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 5.2min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.964 total time= 5.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 5.2min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.962 total time= 5.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  35.7s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.963 total time=  36.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  35.6s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.965 total time=  36.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  36.2s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.959 total time=  36.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  36.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.960 total time=  36.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  36.7s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.959 total time=  37.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  27.4s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.973 total time=  27.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  26.6s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.972 total time=  27.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  26.9s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.970 total time=  27.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  26.7s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.969 total time=  27.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  26.5s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.968 total time=  26.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  32.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.935 total time=  32.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  32.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.939 total time=  32.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  32.2s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.934 total time=  32.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  32.1s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.936 total time=  32.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  33.4s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.930 total time=  34.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.4min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.974 total time= 1.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.3min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.972 total time= 1.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.3min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.969 total time= 1.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.3min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.970 total time= 1.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.3min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.967 total time= 1.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  56.2s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.981 total time=  57.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  55.4s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.982 total time=  56.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  56.7s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.979 total time=  57.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  56.0s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.981 total time=  57.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  56.7s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=1500, transform__tfidf__max_features=500, transform__tfidf__min_df=0.03;, score=0.977 total time=  57.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.963 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.965 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.965 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.0min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.963 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.0min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.960 total time= 1.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  17.3s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.978 total time=  17.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  16.6s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.978 total time=  17.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  17.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.976 total time=  17.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  16.6s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.976 total time=  17.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  16.9s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.973 total time=  17.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  38.4s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.973 total time=  38.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  36.9s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.973 total time=  37.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  37.6s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.970 total time=  38.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  37.5s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.970 total time=  38.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  37.3s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.967 total time=  37.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  32.5s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.957 total time=  33.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  31.5s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.960 total time=  32.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  32.0s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.955 total time=  32.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  31.7s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.955 total time=  32.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  31.7s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.953 total time=  32.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.2min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.951 total time= 2.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.3min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.949 total time= 2.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.3min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.952 total time= 2.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.3min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.946 total time= 2.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.3min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.01;, score=0.943 total time= 2.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  32.0s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.932 total time=  32.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  31.2s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.935 total time=  31.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  31.4s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.929 total time=  31.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  31.2s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.932 total time=  31.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  31.3s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=1100, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.924 total time=  31.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  37.9s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=1300, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.933 total time=  38.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  36.9s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=10, clf__max_features=0.2, clf__n_estimators=1300, transform__tfidf__max_features=500, transform__tfidf__min_df=0.02;, score=0.936 total time=  37.5s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#activating grid search \u001b[39;00m\n\u001b[1;32m      2\u001b[0m rf_random \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(estimator \u001b[38;5;241m=\u001b[39m pipe, \n\u001b[1;32m      3\u001b[0m                            param_distributions\u001b[38;5;241m=\u001b[39m rf_param_grid, \n\u001b[1;32m      4\u001b[0m                            cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m                            scoring \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_micro\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      9\u001b[0m                            random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m fitted_rf_gs \u001b[38;5;241m=\u001b[39m \u001b[43mrf_random\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_remainder1_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_remainder1_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m grid_search_results \u001b[38;5;241m=\u001b[39m fitted_rf_gs\u001b[38;5;241m.\u001b[39mcv_results_\n\u001b[1;32m     15\u001b[0m best_estimator \u001b[38;5;241m=\u001b[39m fitted_rf_gs\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1769\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1768\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1769\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1771\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1772\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1773\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:406\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    405\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:474\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    463\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    466\u001b[0m ]\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 474\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    183\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 185\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#activating grid search \n",
    "rf_random = RandomizedSearchCV(estimator = pipe, \n",
    "                           param_distributions= rf_param_grid, \n",
    "                           cv=5, \n",
    "                           n_iter = 70,\n",
    "                           verbose = 4,\n",
    "                           refit=True,\n",
    "                           scoring = 'f1_micro', \n",
    "                           random_state = 8)\n",
    "\n",
    "fitted_rf_gs = rf_random.fit(X_remainder1_sample, y_remainder1_sample)\n",
    "\n",
    "grid_search_results = fitted_rf_gs.cv_results_\n",
    "\n",
    "best_estimator = fitted_rf_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba35b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the save function\n",
    "write_results_to_s3(grid_search_results, 'rf_random_results_model_1.csv', 'deliverable-slo-bstn-bucket', 'rf_random_results_model_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5050663a",
   "metadata": {},
   "source": [
    "#### Refined Random Forest GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf37ffaf",
   "metadata": {},
   "source": [
    "In order to keep this notebook to be more concise, the evaluation of the Randomized GridSearchCV is not shown, but in general from looking at the top three or four ranked models a more refined hyper-parameter grid can be built out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b016b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from tempfile import mkdtemp\n",
    "from sklearn import svm\n",
    "\n",
    "# Set up a directory to cache the pipeline results\n",
    "\n",
    "cachedir = mkdtemp()\n",
    "\n",
    "#pipeline steps according to tranform, pca, scale, \n",
    "\n",
    "pipe_rf = [('transform', ct),\n",
    "           ('clf', RandomForestClassifier(n_jobs = 1))]\n",
    "\n",
    "pipe = Pipeline(pipe_rf,verbose=4, memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a338b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid on total train set\n",
    "\n",
    "rf_param_grid = [\n",
    "    # Random Forest without PCA\n",
    "    {'transform__tfidf__min_df' : [0.02,0.025,0.03],\n",
    "     'transform__tfidf__max_features': [1000],\n",
    "     'clf': [RandomForestClassifier(n_jobs = 1)],\n",
    "     'clf__max_depth': [20,30,40],\n",
    "     'clf__n_estimators':[100,300,500,700],\n",
    "     'clf__max_features' : [0.2]\n",
    "     }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ce6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  30.8s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.975 total time=  35.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  28.6s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.977 total time=  32.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  27.6s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.977 total time=  31.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  29.4s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.973 total time=  32.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  27.6s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.974 total time=  31.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  21.6s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.980 total time=  25.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  21.8s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.978 total time=  25.2s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  21.2s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.976 total time=  24.7s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  21.2s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.974 total time=  24.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  21.3s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.974 total time=  24.7s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  18.2s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.981 total time=  21.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  18.5s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.980 total time=  22.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  18.4s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.978 total time=  21.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  18.3s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.983 total time=  21.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  18.8s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.980 total time=  22.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.4min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.978 total time= 1.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.4min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.979 total time= 1.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.4min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.976 total time= 1.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.4min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.976 total time= 1.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.4min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.976 total time= 1.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.977 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.979 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.978 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.975 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.0min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.979 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  55.2s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.982 total time=  56.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  55.9s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.980 total time=  57.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  55.4s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.983 total time=  56.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  56.7s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.980 total time=  58.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  56.7s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.977 total time=  58.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.4min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.977 total time= 2.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.4min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.977 total time= 2.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.3min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.978 total time= 2.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.4min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.977 total time= 2.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.4min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.976 total time= 2.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.9min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.979 total time= 1.9min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.8min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.980 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.979 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.9min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.975 total time= 2.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.8min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.977 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.5min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.983 total time= 1.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.5min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.982 total time= 1.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.5min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.981 total time= 1.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.5min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.980 total time= 1.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.6min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.981 total time= 1.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 3.3min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.978 total time= 3.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 3.3min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.977 total time= 3.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 3.2min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.976 total time= 3.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 3.3min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.974 total time= 3.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 3.2min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.975 total time= 3.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.6min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.979 total time= 2.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.6min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.979 total time= 2.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.5min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.979 total time= 2.5min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.5min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.976 total time= 2.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.5min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.977 total time= 2.5min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.3min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.983 total time= 2.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.2min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.982 total time= 2.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.4min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.981 total time= 2.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.2min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.980 total time= 2.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.3min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.980 total time= 2.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  31.8s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.993 total time=  32.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  31.2s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.993 total time=  32.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  30.2s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time=  31.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  31.2s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time=  32.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  30.6s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time=  31.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.7s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.994 total time=  24.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  24.2s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.994 total time=  25.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.8s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time=  24.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.8s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.994 total time=  24.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.5s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time=  24.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.8s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.994 total time=  21.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.6s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=  21.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.0s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time=  21.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.5s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=  21.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.3s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time=  21.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.6min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time= 1.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.5min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time= 1.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.5min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time= 1.5min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.6min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time= 1.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.5min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time= 1.5min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.994 total time= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.994 total time= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.0min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time= 1.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.0min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time= 1.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.0min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time= 1.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.0min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time= 1.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.0min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.6min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time= 2.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.6min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time= 2.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.5min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time= 2.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.6min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time= 2.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.6min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time= 2.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.0min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.994 total time= 2.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.0min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time= 2.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.9min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time= 1.9min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.9min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time= 1.9min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.9min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time= 2.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time= 1.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time= 1.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 1.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time= 1.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 1.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 3.6min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time= 3.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 3.7min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time= 3.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 3.6min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time= 3.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 3.7min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time= 3.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 3.6min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time= 3.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.8min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time= 2.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.7min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time= 2.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.7min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time= 2.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.7min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time= 2.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.7min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time= 2.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.3min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time= 2.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.3min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time= 2.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.5min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 2.5min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.3min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 2.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.4min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 2.5min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  31.3s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time=  32.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  32.5s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time=  33.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  30.9s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time=  31.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  33.4s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time=  34.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  31.6s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time=  32.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  25.0s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time=  26.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.2s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time=  24.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.6s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.996 total time=  24.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.7s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time=  24.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  23.4s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.996 total time=  24.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.6s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time=  21.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  21.0s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time=  22.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  19.7s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time=  20.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.4s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time=  21.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  20.4s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=100, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time=  21.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.6min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time= 1.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.6min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time= 1.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.5min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time= 1.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.6min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time= 1.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.5min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time= 1.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.996 total time= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.996 total time= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.996 total time= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.0min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 1.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  59.9s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 1.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  60.0s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 1.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.0min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 1.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.0min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=300, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 1.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.7min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time= 2.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.7min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time= 2.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.6min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time= 2.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.7min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time= 2.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.6min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time= 2.6min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.0min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time= 2.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.2min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time= 2.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.0min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.996 total time= 2.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.0min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.996 total time= 2.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.0min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.996 total time= 2.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.8min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.9min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 1.9min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 1.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=500, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 3.8min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time= 3.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 3.7min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time= 3.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 3.7min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time= 3.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 3.7min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time= 3.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 3.6min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time= 3.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.9min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time= 3.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.9min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.995 total time= 3.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.8min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.996 total time= 2.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.8min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.996 total time= 2.9min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.8min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.996 total time= 2.9min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.3min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 2.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.3min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 2.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.4min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 2.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.3min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 2.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.5min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=40, clf__max_features=0.2, clf__n_estimators=700, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time= 2.5min\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   2.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.2min\n"
     ]
    }
   ],
   "source": [
    "#more refined grid search to total train set \n",
    "rf_gs = GridSearchCV(estimator = pipe, \n",
    "                    param_grid = rf_param_grid, \n",
    "                    cv=5, \n",
    "                    n_jobs=1,\n",
    "                    verbose = 4,\n",
    "                    refit=True,\n",
    "                    scoring = 'f1_micro')\n",
    "\n",
    "fitted_rf_gs = rf_gs.fit(X_remainder1, y_remainder1)\n",
    "\n",
    "grid_search_results = fitted_rf_gs.cv_results_\n",
    "\n",
    "best_estimator = fitted_rf_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a51f6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickled_best_rf_model1.pkl has been saved to deliverable-slo-bstn-bucket\n"
     ]
    }
   ],
   "source": [
    "# saving random forest pickle file\n",
    "save_best_model(best_estimator, 'pickled_best_rf_model1.pkl', bucket='deliverable-slo-bstn-bucket', key='pickled_best_rf_model1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f432ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='/tmp/tmpnsz3m1op',\n",
      "         steps=[('transform',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('tfidf',\n",
      "                                                  TfidfVectorizer(max_features=1000,\n",
      "                                                                  min_df=0.03,\n",
      "                                                                  stop_words='english'),\n",
      "                                                  'reviewText'),\n",
      "                                                 ('scale', StandardScaler(),\n",
      "                                                  Index(['overall', 'vote', 'verified', 'price_USD', 'ranking',\n",
      "       'also_buy_counts', 'also_view_counts', 'c_accessories',\n",
      "       'c_bath and sh...\n",
      "       'm_Laura Geller', 'm_Mario Badescu', 'm_Mustela', 'm_NUXE',\n",
      "       'm_Natura Bisse', 'm_OPI', 'm_Oribe', 'm_Other', 'm_PCA Skin',\n",
      "       'm_Paul Mitchell', 'm_Pureology', 'm_RUSK', 'm_Red Flower',\n",
      "       'm_Rene Furterer', 'm_Stila', 'm_StriVectin', 'm_TS',\n",
      "       'm_The Art of Shaving', 'm_Vichy', 'm_theBalm'],\n",
      "      dtype='object'))])),\n",
      "                ('clf',\n",
      "                 RandomForestClassifier(max_depth=40, max_features=0.2,\n",
      "                                        n_estimators=500, n_jobs=1))],\n",
      "         verbose=4)\n"
     ]
    }
   ],
   "source": [
    "print(best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc52f97",
   "metadata": {
    "id": "7cc52f97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Random Forest f1-micro score on the remainder set: 0.9994288224956063\n",
      "The best Random Forest f1-micro score on the validation set: 0.9993507159211291\n"
     ]
    }
   ],
   "source": [
    "# Sanity check on the pickled model\n",
    "\n",
    "filename = 'pickled_best_rf_model1.pkl'\n",
    "pickled_best = joblib.load(filename)\n",
    "\n",
    "# Print the accuracies\n",
    "print(f\"The best Random Forest f1-micro score on the remainder set: {pickled_best.score(X_train1, y_train1)}\")\n",
    "print(f\"The best Random Forest f1-micro score on the validation set: {pickled_best.score(X_val1, y_val1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WUBdNWshLQ09",
   "metadata": {
    "id": "WUBdNWshLQ09"
   },
   "source": [
    "| **Model**              | **F1-Micro Score** | **Best Parameters TFIDF**          | **Best Parameters Scaler/PCA** | **Best Parameters Model**                                 | **Method**         |\n",
    "|------------------------|---------------------|------------------------------------|--------------------------------|-----------------------------------------------------------|--------------------|\n",
    "| Logistic Regression    | 90.67%              | [min_df=0.01, max_features = 500]  | [StandardScaler, no PCA]       | [lbfgs, penalty = L2, C = 0.001]                          | RandomizedSearchCV |\n",
    "| Support Vector Machine | 91.56%              | [min_df=0.02, max_features = 500]  | [MinMaxScaler, PCA(0.9)]       | [rbf, gamma = 0.1, C = 10]                                | RandomizedSearchCV |\n",
    "| Support Vector Machine | 92.67%              | [min_df=0.02, max_features = 1000] | [MinMaxScaler, PCA(0.95)]      | [rbf, gamma = 0.1, C = 10]                                | GridSearchCV       |\n",
    "| Random Forest          | 99.67%              | [min_df=0.03, max_features = 500]  | -------------------            | [n_estimators = 700, max_depth = 40, max_features = 0.2]  | RandomizedSearchCV |\n",
    "| Random Forest          | 99.94%              | [min_df=0.03, max_features = 1000] | -------------------            | [n_estimators = 500, max_depth = 40 , max_features = 0.2] | GridSearchCV       |\n",
    "| Baseline               | 88.85%              | -------------------                | -------------------            | -------------------------                                 | For comparison     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57fa7ba",
   "metadata": {
    "id": "f57fa7ba"
   },
   "source": [
    "Between Logistic Regression and SVM to Random Forest, we see a 7% increase in the F1.micro score, this is promising for our model, but we should be slightly cautious in the way that we interpret this. We may be over fitting to the train set. In terms of evaluating the hyper-parameters from the RandomizedSearchCV to the refined search something we should look at is that the number of trees reduced from 700 to 500, which is not the best for generalization since it over fits more when there are less trees (but is better computationally). In addition, the max_depth is fairly large but we can speak to this more in our model evaluation section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2fc849",
   "metadata": {
    "id": "af2fc849"
   },
   "source": [
    "### <font color='256D85'> XGBoost Modelling <font> <a id=\"3.d\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b45749",
   "metadata": {
    "id": "85b45749"
   },
   "source": [
    "Finally, we will be trying out XGBoost, which stands for eXtreme Gradient Boosting. This is a combination of gradient boosting and decision trees, all used in order to make its predictions. More specifically, it builds multiple decision trees sequentially, each time trying to minimize the error of the previous tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da3a568",
   "metadata": {},
   "source": [
    "#### Randomized XGBoost SearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516804f5",
   "metadata": {},
   "source": [
    "Before we start our pipeline we can define the most important hyperparameters specific to XGBoost: \n",
    "- **max_depth_range**: Indicates the depth of the tree, increasing it increases the model complexity. \n",
    "- **n_estimators**: The number of trees in the model. \n",
    "- **learning_rate**: Controls the step size at each iteration of the gradient boosting process and is a value set between 0 and 1. \n",
    "- **colsample_bytree_range**: The fraction of colimmns to be randomly samples for each tree. \n",
    "- **Gamma**: The minimum loss reduction required to make a split. \n",
    "\n",
    "Note: scaling and dimension reducing is not required in this model since like Random Forest it is a tree-based model and can select the most important features for the split at each node of the tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe17c22c",
   "metadata": {
    "id": "fe17c22c"
   },
   "outputs": [],
   "source": [
    "#hyper parameters XGBoost \n",
    "gamma_range = [i/10.0 for i in range(0,5)]\n",
    "colsample_bytree_range = [i/10.0 \n",
    "                          for i in range(3,10)]\n",
    "max_depth_range = list(range(3,21,3))\n",
    "learning_rate_range = [0.01 , 0.1, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from tempfile import mkdtemp\n",
    "from sklearn import svm\n",
    "\n",
    "# Set up a directory to cache the pipeline results\n",
    "\n",
    "cachedir = mkdtemp()\n",
    "\n",
    "#pipeline steps according to tranform, pca, scale, \n",
    "\n",
    "pipe_boost = [('transform', ct),\n",
    "              ('clf', XGBClassifier())]\n",
    "\n",
    "pipe = Pipeline(pipe_boost,verbose=4, memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677972df",
   "metadata": {
    "id": "677972df"
   },
   "outputs": [],
   "source": [
    "# Parameter grid\n",
    "\n",
    "boost_param_grid = [\n",
    "    # boost without PCA\n",
    "    {'transform__tfidf__min_df' : vectorize_mindf_list ,\n",
    "     'transform__tfidf__max_features': [1000],\n",
    "     'clf': [XGBClassifier()],\n",
    "     'clf__gamma': gamma_range,\n",
    "     'clf__colsample_bytree':colsample_bytree_range,\n",
    "     'clf__max_depth':max_depth_range,\n",
    "     'clf__learning_rate' :learning_rate_range\n",
    "     }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e03a2",
   "metadata": {
    "id": "7b1e03a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.4, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.995 total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.4, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.995 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.4, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.996 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.4, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.993 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.4, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.992 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.969 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.971 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.966 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.967 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.960 total time=   2.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.974 total time=   1.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.974 total time=   1.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.973 total time=   1.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.971 total time=   1.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.972 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time=   1.7s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.992 total time=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.997 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.997 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.996 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.996 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.994 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.992 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.992 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.973 total time=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.973 total time=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.973 total time=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.973 total time=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.970 total time=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.935 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.930 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.934 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.934 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.927 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.2s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time=   1.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.974 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.963 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.968 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.968 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.964 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.964 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.959 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.967 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.965 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.958 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.961 total time=   1.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.960 total time=   1.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.956 total time=   1.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.956 total time=   1.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.950 total time=   1.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.905 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.906 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.905 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.904 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.901 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.903 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.906 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.904 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.904 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.901 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.925 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.926 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.923 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.928 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.921 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.0, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.966 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.0, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.964 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.0, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.970 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.0, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.967 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.0, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.965 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time=   1.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.2s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time=   1.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=   1.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=   1.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.2s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.993 total time=   1.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.910 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.909 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.908 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.906 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.905 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.994 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.960 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.962 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.959 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.957 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.956 total time=   1.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.4, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.903 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.4, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.905 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.4, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.904 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.4, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.904 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.4, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.901 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.997 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.997 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.996 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.996 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.993 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.928 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.933 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.928 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.929 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.925 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.996 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.996 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.996 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.997 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.992 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.4, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.973 total time=   1.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.4, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.972 total time=   1.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.4, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.970 total time=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.4, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.972 total time=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.4, clf__learning_rate=0.01, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.968 total time=   1.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.944 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.944 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.943 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.943 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.939 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.994 total time=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.995 total time=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.993 total time=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.994 total time=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.992 total time=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.970 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.969 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.973 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.974 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.964 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.929 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.930 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.926 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.928 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.926 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.906 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.908 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.908 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.905 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.904 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.0, clf__learning_rate=0.1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.987 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.0, clf__learning_rate=0.1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.986 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.0, clf__learning_rate=0.1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.986 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.0, clf__learning_rate=0.1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.988 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.0, clf__learning_rate=0.1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.984 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.941 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.944 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.940 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.938 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.934 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.993 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.931 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.936 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.931 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.930 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.927 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.992 total time=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.939 total time=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.940 total time=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.935 total time=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.936 total time=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.934 total time=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.994 total time=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.991 total time=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.994 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.995 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.994 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.995 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.993 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.991 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.992 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.906 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.908 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.908 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.905 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.903 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=   1.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time=   1.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.992 total time=   1.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.993 total time=   1.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.929 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.933 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.933 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.932 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.924 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.981 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.980 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.977 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.975 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.976 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.944 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.944 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.942 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.943 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.939 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.4, clf__learning_rate=1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.4, clf__learning_rate=1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time=   1.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.4, clf__learning_rate=1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.8s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.4, clf__learning_rate=1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.4, clf__learning_rate=1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.994 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.929 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.934 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.934 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.933 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.924 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time=   1.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.7s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time=   1.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.993 total time=   2.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.7s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time=   2.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.993 total time=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.1s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.957 total time=   1.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.0s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.953 total time=   1.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.0s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.951 total time=   1.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.0s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.950 total time=   1.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.0s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.945 total time=   1.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.972 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.969 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.968 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.965 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.964 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.989 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.986 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.988 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.986 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.980 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.955 total time=   1.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.956 total time=   1.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.0s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.955 total time=   1.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.952 total time=   1.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.946 total time=   1.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.937 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.942 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.935 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.937 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=0.01, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.934 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.994 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.987 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.988 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.989 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.987 total time=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.991 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.992 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.3, clf__learning_rate=1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.992 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.996 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.995 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.994 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.996 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=   0.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.995 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.996 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.995 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.5s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.994 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.5, clf__gamma=0.2, clf__learning_rate=1, clf__max_depth=12, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.994 total time=   0.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.4, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.906 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.4, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.909 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.4, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.908 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.4, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.908 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.2s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.4, clf__learning_rate=0.01, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.904 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.0s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.994 total time=   1.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.0s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.995 total time=   1.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.994 total time=   1.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.994 total time=   1.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.9s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0.3, clf__learning_rate=0.1, clf__max_depth=18, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.993 total time=   1.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.960 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.962 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.965 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.964 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.954 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.918 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.916 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.913 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.922 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.4, clf__gamma=0.0, clf__learning_rate=0.01, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.917 total time=   0.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.930 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.931 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.932 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.932 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.925 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.995 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.6s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0.1, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   0.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.930 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.931 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.932 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.932 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0.2, clf__learning_rate=0.1, clf__max_depth=3, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.923 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.1s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.956 total time=   1.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.1s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.955 total time=   1.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.1s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.955 total time=   1.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.1s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.951 total time=   1.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.1s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.9, clf__gamma=0.2, clf__learning_rate=0.01, clf__max_depth=15, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.01;, score=0.947 total time=   1.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.954 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.956 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.958 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.957 total time=   0.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.3s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.3, clf__gamma=0.4, clf__learning_rate=0.1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.956 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   0.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.7s\n"
     ]
    }
   ],
   "source": [
    "#activating grid search \n",
    "boost_random = RandomizedSearchCV(estimator = pipe, \n",
    "                           param_distributions= boost_param_grid, \n",
    "                           cv=5, \n",
    "                           n_iter = 70,\n",
    "                           n_jobs=1,\n",
    "                           verbose = 4,\n",
    "                           refit=True,\n",
    "                           scoring = 'f1_micro', \n",
    "                           random_state = 8)\n",
    "\n",
    "fitted_boost_random = boost_random.fit(X_remainder1_sample, y_remainder1_sample)\n",
    "\n",
    "\n",
    "grid_search_results = fitted_boost_random.cv_results_\n",
    "\n",
    "best_estimator = fitted_boost_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8662d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boost_random_results_model_1.csv has been saved to deliverable-slo-bstn-bucket\n"
     ]
    }
   ],
   "source": [
    "#calling the save function\n",
    "write_results_to_s3(grid_search_results, 'boost_random_results_model_1.csv', 'deliverable-slo-bstn-bucket', 'boost_random_results_model_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d169e2",
   "metadata": {},
   "source": [
    "#### Refined XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615934a1",
   "metadata": {},
   "source": [
    "Let's go through the process of our pipeline, refined parameter grid and activation and see what results we get. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from tempfile import mkdtemp\n",
    "from sklearn import svm\n",
    "\n",
    "# Set up a directory to cache the pipeline results\n",
    "\n",
    "cachedir = mkdtemp()\n",
    "\n",
    "#pipeline steps according to tranform, pca, scale, \n",
    "\n",
    "pipe_boost = [('transform', ct),\n",
    "              ('clf', XGBClassifier())]\n",
    "\n",
    "pipe = Pipeline(pipe_boost,verbose=4, memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uyKOMYpsKKE8",
   "metadata": {
    "id": "uyKOMYpsKKE8"
   },
   "outputs": [],
   "source": [
    "# Parameter grid\n",
    "\n",
    "boost_param_grid2 = [\n",
    "    # boost without PCA\n",
    "    {'transform__tfidf__min_df' : [0.02,0.025,0.03,0.035,0.04],\n",
    "     'transform__tfidf__max_features': [1000],\n",
    "     'clf': [XGBClassifier()],\n",
    "     'clf__gamma': [0],\n",
    "     'clf__colsample_bytree':[0.6,0.7,0.8],\n",
    "     'clf__max_depth':[6,7,8,9],\n",
    "     'clf__learning_rate' :[1]\n",
    "     }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d999f3",
   "metadata": {
    "id": "40d999f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.935 total time=   6.6s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.901 total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.839 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   5.6s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   5.6s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.894 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   5.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   5.1s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   5.0s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.954 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.949 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.971 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.908 total time=   4.6s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.910 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.986 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.924 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   4.6s\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   1.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   4.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.5s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   4.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.1s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   4.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.5s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.5s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   3.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.977 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.950 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.870 total time=   2.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.4s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.881 total time=   2.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.1s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.799 total time=   2.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.7s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   2.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.7s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   2.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.998 total time=   2.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.7s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.998 total time=   2.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.964 total time=   2.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   2.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   2.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   2.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   2.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.3s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.920 total time=   2.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.8s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.977 total time=   3.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.8s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   3.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.8s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   3.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.9s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   3.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.8s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   3.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   3.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   3.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   3.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.935 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   3.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.3s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.958 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.973 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.3s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.998 total time=   2.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   2.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.974 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.998 total time=   2.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   2.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.934 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.1s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   4.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.0s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   3.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.1s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   4.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.0s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   3.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.7s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.7s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.7s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.970 total time=   3.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   4.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.959 total time=   4.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.5s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.5s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.5s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.966 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.998 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.978 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.6, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.5s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.960 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.932 total time=   3.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.913 total time=   3.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.935 total time=   3.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   3.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.946 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   2.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   2.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   2.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   2.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.880 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.993 total time=   2.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   2.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   2.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   2.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   2.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   2.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.6s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   2.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.8s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   3.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.927 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.8s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   3.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.944 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.8s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   3.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.972 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.3s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.988 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.962 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.978 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.921 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.998 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.7s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.962 total time=   3.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   3.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.965 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.1s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   4.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.1s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   4.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.1s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   3.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.9s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.955 total time=   3.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.1s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   4.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.961 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.5s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   3.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   3.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   3.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.5s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   3.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   3.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   3.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   3.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   3.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.3s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.972 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   3.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.3s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.3s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.998 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.963 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.5s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.980 total time=   3.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.965 total time=   2.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.954 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.0s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.961 total time=   3.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.933 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   4.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.4s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   4.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   4.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.8s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   3.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.7s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   3.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.7s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   3.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.7s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   3.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.7s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   3.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.7s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.998 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.5s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.929 total time=   2.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.7, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   3.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   4.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.940 total time=   5.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.8s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.906 total time=   3.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.905 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.7s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.7s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   3.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.877 total time=   3.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.3s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.933 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.899 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.918 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   2.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.941 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.913 total time=   2.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   2.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.998 total time=   2.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   2.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.9s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.930 total time=   2.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.944 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.881 total time=   2.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.8s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=6, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   2.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.1s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   3.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.7s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.917 total time=   3.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.910 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.1s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   3.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.0s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   3.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   1.1s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.889 total time=   1.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.998 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.948 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.2s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.998 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=7, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.4s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   4.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   4.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.4s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   4.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.5s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   4.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   4.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.0s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   3.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   4.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.9s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   3.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.9s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   3.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.3s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.920 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.5s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   3.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.5s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   3.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.5s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   3.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   3.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.3s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.959 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   3.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   3.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.945 total time=   3.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.998 total time=   3.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.4s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   3.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.928 total time=   2.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.3s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   3.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.3s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   3.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.0s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.949 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.1s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=8, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.936 total time=   2.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.8s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   4.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.8s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   4.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.7s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.997 total time=   4.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.9s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   4.7s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.7s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.02;, score=0.998 total time=   4.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.3s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   4.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.3s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   4.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.2s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.997 total time=   4.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.2s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   4.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.2s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.025;, score=0.998 total time=   4.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.7s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   3.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.7s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   3.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.7s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.998 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.7s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.7s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.03;, score=0.997 total time=   3.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.998 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.035;, score=0.997 total time=   3.5s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 1/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 2/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.3s\n",
      "[CV 3/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.970 total time=   3.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 4/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.998 total time=   3.4s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   2.6s\n",
      "[CV 5/5] END clf=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...), clf__colsample_bytree=0.8, clf__gamma=0, clf__learning_rate=1, clf__max_depth=9, transform__tfidf__max_features=1000, transform__tfidf__min_df=0.04;, score=0.997 total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1671: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=   2.2s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=   3.0s\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'tfidf_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 13\u001b[0m\n\u001b[1;32m      2\u001b[0m boost_random \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator \u001b[38;5;241m=\u001b[39m pipe, \n\u001b[1;32m      3\u001b[0m                            param_grid \u001b[38;5;241m=\u001b[39m boost_param_grid2, \n\u001b[1;32m      4\u001b[0m                            cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m                            refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m                            scoring \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_micro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m fitted_boost_random \u001b[38;5;241m=\u001b[39m boost_random\u001b[38;5;241m.\u001b[39mfit(X_remainder1, y_remainder1)\n\u001b[0;32m---> 13\u001b[0m grid_search_results \u001b[38;5;241m=\u001b[39m \u001b[43mfitted_boost_random\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtfidf_results_\u001b[49m\n\u001b[1;32m     15\u001b[0m best_estimator \u001b[38;5;241m=\u001b[39m fitted_boost_random\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'tfidf_results_'"
     ]
    }
   ],
   "source": [
    "#activating grid search \n",
    "boost_random = GridSearchCV(estimator = pipe, \n",
    "                           param_grid = boost_param_grid2, \n",
    "                           cv=5, \n",
    "                           n_jobs=1,\n",
    "                           verbose = 4,\n",
    "                           refit=True,\n",
    "                           scoring = 'f1_micro')\n",
    "\n",
    "fitted_boost_random = boost_random.fit(X_remainder1, y_remainder1)\n",
    "\n",
    "\n",
    "grid_search_results = fitted_boost_random.cv_results_\n",
    "\n",
    "best_estimator = fitted_boost_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b1dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickled_best_boost_model1.pkl has been saved to deliverable-slo-bstn-bucket\n"
     ]
    }
   ],
   "source": [
    "# saving random forest pickle file\n",
    "save_best_model(best_estimator, 'pickled_best_boost_model1.pkl', bucket='deliverable-slo-bstn-bucket', key='pickled_best_boost_model1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eef42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "               gamma=0, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=1, max_bin=None,\n",
       "               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "               predictor=None, random_state=None, ...),\n",
       " 'clf__colsample_bytree': 0.8,\n",
       " 'clf__gamma': 0,\n",
       " 'clf__learning_rate': 1,\n",
       " 'clf__max_depth': 9,\n",
       " 'transform__tfidf__max_features': 1000,\n",
       " 'transform__tfidf__min_df': 0.025}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at best_parameters for refined grid search\n",
    "fitted_boost_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e1d692",
   "metadata": {
    "id": "f3e1d692"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best XGBoost F1-Micro score on the train set: 0.9994288224956063\n",
      "The best XGBoost F1-Micro on the validation set: 0.9993507159211291\n"
     ]
    }
   ],
   "source": [
    "# Sanity check on the pickled model\n",
    "filename = 'pickled_best_boost_model1.pkl'\n",
    "pickled_best = joblib.load(filename)\n",
    "\n",
    "# Print the f1-scores\n",
    "print(f\"The best XGBoost F1-Micro score on the train set: {pickled_best.score(X_train1, y_train1)}\")\n",
    "print(f\"The best XGBoost F1-Micro on the validation set: {pickled_best.score(X_val1, y_val1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb37d11f",
   "metadata": {},
   "source": [
    "Overall, we see some very similar results compared to Random Forest. Let's put this in our summary table below: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663c8a16",
   "metadata": {},
   "source": [
    "| **Model**              | **F1-Micro Score** | **Best Parameters TFIDF**           | **Best Parameters Scaler/PCA** | **Best Parameters Model**                                             | **Method**         |\n",
    "|------------------------|---------------------|-------------------------------------|--------------------------------|-----------------------------------------------------------------------|--------------------|\n",
    "| Logistic Regression    | 90.67%              | [min_df=0.01, max_features = 500]   | [StandardScaler, no PCA]       | [lbfgs, penalty = L2, C = 0.001]                                      | RandomizedSearchCV |\n",
    "| Support Vector Machine | 91.56%              | [min_df=0.02, max_features = 500]   | [MinMaxScaler, PCA(0.9)]       | [rbf, gamma = 0.1, C = 10]                                            | RandomizedSearchCV |\n",
    "| Support Vector Machine | 92.67%              | [min_df=0.02, max_features = 1000]  | [MinMaxScaler, PCA(0.95)]      | [rbf, gamma = 0.1, C = 10]                                            | GridSearchCV       |\n",
    "| Random Forest          | 99.67%              | [min_df=0.03, max_features = 500]   | -------------------            | [n_estimators = 700, max_depth = 40, max_features = 0.2]              | RandomizedSearchCV |\n",
    "| Random Forest          | 99.94%              | [min_df=0.03, max_features = 1000]  | -------------------            | [n_estimators = 500, max_depth = 40 , max_features = 0.2]             | GridSearchCV       |\n",
    "| XGBoost                | 99.71%              | [min_df=0.03, max_features = 500]   | -------------------            | [colsample bytree = 0.6, gamma = 0, learning rate = 1, max_depth = 6, n_estimators = 100] | RandomizedSearchCV |\n",
    "| XGBoost                | 99.93%              | [min_df=0.025, max_features = 1000] | -------------------            | [colsample bytree = 0.8, gamma = 0, learning rate = 1, max_depth = 9, n_estimators = 100] | GridSearchCV       |\n",
    "| Baseline               | 88.85%              | -------------------                 | -------------------            | -------------------------                                             | For comparison     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315abaab",
   "metadata": {},
   "source": [
    "XGBoost is showing very similar performance with the F1-score at 99.93%, which looks promising upon first glance. However, when we take a closer look into the hyper-parameter tuning that it had it's best model on, it is highly likely that the model is overfitted. If we take a look at the learning rate this is fairly high at 1 since usually the most optimal parameter sits around 0.01-0.3 and is most probably causing the model to overfit to the noise in the data. We can speak more to this in the next section of Model Evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2109f99d",
   "metadata": {},
   "source": [
    "## <font color='256D85'> Model Evaluation <font> <a id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde54196",
   "metadata": {},
   "source": [
    "In this section we will go through how we are going to evaluate which model is best for our trend searcher. In the previous section we have summarized the results from our GridSearchCV outputs in a table and it is safe to say that Random Forest and XGBoost were best performers, each obtaining a 99% F1-score. One of the first ways we can evaluate these models is with a confusion matrix. Let's first load the best hyper parameters in for each model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9c17b6",
   "metadata": {},
   "source": [
    "#### Load in Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "92264b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the output after vectorization is: (67563, 126)\n"
     ]
    }
   ],
   "source": [
    "#count vectorizer function\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "\n",
    "ct_train_rf = ColumnTransformer([\n",
    "        ('tfidf', TfidfVectorizer(stop_words=\"english\",min_df=0.03,max_features=1000), 'reviewText')\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# 2. Fit \n",
    "ct_train_rf.fit(X_train1,y_train1)\n",
    "\n",
    "# 3. Transform\n",
    "X_train_tfidf_rf = ct_train_rf.transform(X_train1)\n",
    "X_val_tfidf_rf = ct_train_rf.transform(X_val1)\n",
    "X_test_tfidf_rf = ct_train_rf.transform(X_test1)\n",
    "print(f\"Shape of the output after vectorization is: {X_train_tfidf_rf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "acf4a3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=40, max_features=0.2, n_estimators=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=40, max_features=0.2, n_estimators=500)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=40, max_features=0.2, n_estimators=500)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate the model\n",
    "rf = RandomForestClassifier(n_estimators = 500, \n",
    "                            max_features = 0.2, \n",
    "                            max_depth = 40\n",
    ")\n",
    "#fit\n",
    "rf.fit(X_train_tfidf_rf,y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a0d47c",
   "metadata": {},
   "source": [
    "#### Loading in XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1783be99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the output after vectorization is: (67563, 140)\n"
     ]
    }
   ],
   "source": [
    "#count vectorizer function\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "\n",
    "ct_train_boost = ColumnTransformer([\n",
    "        ('tfidf', TfidfVectorizer( stop_words=\"english\",min_df=0.025,max_features=1000), 'reviewText')\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "# 2. Fit \n",
    "ct_train_boost.fit(X_train1)\n",
    "\n",
    "# 3. Transform\n",
    "X_train_tfidf_boost = ct_train_boost.transform(X_train1)\n",
    "X_val_tfidf_boost = ct_train_boost.transform(X_val1)\n",
    "print(f\"Shape of the output after vectorization is: {X_train_tfidf_boost.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ae9740cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost = XGBClassifier(colsample_bytree=0.8, \n",
    "                      gamma=0, \n",
    "                      learning_rate=1,\n",
    "                      max_depth=9\n",
    ")\n",
    "\n",
    "boost.fit(X_train_tfidf_boost, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e4b5df",
   "metadata": {},
   "source": [
    "#### Confusion matrices and Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99346a65",
   "metadata": {},
   "source": [
    "Now we can load in the classification reports for each model and the confusion matrices as well. The classification report will let us see how the model performed against our classifiers in terms of percentages, and the confusion matrices will return the number of absolute true positives, true negatives, false negatives and false positive predictions made by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "659b3936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### CLASSIFICATION REPORT FOR RANDOM FOREST #######\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     25729\n",
      "           1       0.98      0.98      0.98      3227\n",
      "\n",
      "    accuracy                           1.00     28956\n",
      "   macro avg       0.99      0.99      0.99     28956\n",
      "weighted avg       1.00      1.00      1.00     28956\n",
      "\n",
      "###### CLASSIFICATION REPORT FOR XGBOOST ######\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     25729\n",
      "           1       0.99      0.99      0.99      3227\n",
      "\n",
      "    accuracy                           1.00     28956\n",
      "   macro avg       0.99      0.99      0.99     28956\n",
      "weighted avg       1.00      1.00      1.00     28956\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x216 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "#Confusion Matrix Random Forest\n",
    "ConfusionMatrixDisplay.from_estimator(rf, X_val_tfidf_rf, y_val1, ax=axes[0])\n",
    "axes[0].set_title('Random Forest Confusion Matrix')\n",
    "#Confusion Matrix Boost\n",
    "ConfusionMatrixDisplay.from_estimator(boost, X_val_tfidf_boost, y_val1, ax=axes[1])\n",
    "axes[1].set_title('XGBoost Confusion Matrix')\n",
    "\n",
    "#classification report for Random Forest\n",
    "print(\"###### CLASSIFICATION REPORT FOR RANDOM FOREST #######\")\n",
    "y_pred = rf.predict(X_val_tfidf_rf)\n",
    "print(classification_report(y_val1, y_pred))\n",
    "\n",
    "#classification report for Boost\n",
    "print(\"###### CLASSIFICATION REPORT FOR XGBOOST ######\")\n",
    "y_pred = boost.predict(X_val_tfidf_boost)\n",
    "print(classification_report(y_val1, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4994d9ea",
   "metadata": {},
   "source": [
    "The classification reports for both models are looking like we are achieving very high levels of recall and precision for both of our classes 1 (trending) and 0 (non-trending) with XGBoost performing 1% better with regards to predicting trending class one. How is this reflected in the confusion matrices? Something to pay attention to here is the False Negatives and False Positives whereby both models have very low absolute numbers of these at less than 2%, but that Random Forest has a higher level of False Positives than False Negatives and XGBoost has the inverse relationship. \n",
    "\n",
    "Which one is better? If we think about our end goal for this project the user of the model wants to be able to predict trending beauty products, so let's consider two scenarios. Would the user rather have variety and range of predictions and see more false positives that aren't truly trending products or would we want to have more concise trend predictions and have more products go undetected? We would probably want a balance of the two but have a higher false positive rate than false negative rate, but these numbers are very little between the models, so it will come down to model interpretability. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18f758f",
   "metadata": {},
   "source": [
    "### <font color='256D85'> Deciding between Random Forest and XGBoost <font> <a id=\"4.a\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c591dc",
   "metadata": {},
   "source": [
    "After having seen the confusion matrices, the classification reports, and the final hyper-parameters for our model how we can decide between Random Forest and XGBoost models when they have very similar model scores? Something that is important here is interpretability, and being able to define what are the most important features in the model. The end user of this model is aimed at a stakeholder in the innovation or marketing department of a company, so keeping the final model as simple as possible is the goal. This is why ultimately we will select Random Forest for 2 key reasons: \n",
    "1. Random Forest models are easier to interpret and explain compared to XGBoost models. Since Random Forest models use decision trees, we can easily understand how the model makes decisions by looking at the decision paths but XGboost requires more understanding. \n",
    "2. After having evaluated the hyper-parameters of our model there was a slight concern of XGBoost having over fitted predictions to the training set based on its hyper-parameters, the concern is there also for Random Forest but we have a higher level of confidence that it is less sensitive to outliers. \n",
    "\n",
    "The Random Forest Model has been selected as our model for the project. We are still slightly concerned that it is over fitting slightly to the training data, but we can start by looking at the most important features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b737f8",
   "metadata": {},
   "source": [
    "### <font color='256D85'> Random Forest Interpretability <font> <a id=\"4.b\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b04f6ac",
   "metadata": {},
   "source": [
    "A way to interpret the model chosen is through looking at its Feature Importance which gives a score for all of the given input features for the model. Below since we have 126 columns in our model we will evaluate the Top 15 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a143e96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature importance plot\n",
    "sorted_idx = rf.feature_importances_.argsort() #sorted\n",
    "top15_sorted_idx = rf.feature_importances_.argsort()[-15:] #sorting by top 15\n",
    "plt.barh(ct_train_rf.get_feature_names_out()[top15_sorted_idx ], rf.feature_importances_[top15_sorted_idx ], color ='navy')\n",
    "plt.xlabel(\"Random Forest Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba1fe81",
   "metadata": {},
   "source": [
    "The way we can interpret the plot above is that the higher the value, the more important the feature is to predict the target variable. Here we can see some interesting insights: \n",
    "- Ranking has the largest importance in the model, this makes sense so now we know that ranking influences the increasing review counts, we did check the correlations between our target and this column and they weren't highly correlated with each other to begin with. \n",
    "- The Tf-idf Vectorizer picked up similar points to what our feature engineering did in terms of skincare, make-up where skincare brands such as Mario Badescu played a role in indicating its trendiness. \n",
    "- `price`, `also_view_counts` and `also_buy_counts` all played a fairly large part in driving the results of the model, indicating that trending products are more sensitive to price and mentions in other product listings. \n",
    "\n",
    "It may be worth to note that the feature_importances output can be a bit misleading as it tends to inflate the importances for the continuous features or features with many unique categorical values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25338d5c",
   "metadata": {},
   "source": [
    "#### Can we make any model improvements? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df57ae39",
   "metadata": {},
   "source": [
    "In the previous section we described how our final Random Forest model is most likely over fitting with a 99.94% F1-micro score. Therefore, we want to make our final model more regularized. We can do so by adjusting the hyper-parameters slightly and we are also interested in vectorizing both of the `reviewText` and `product_description` columns, however this may come at the cost of having more features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15deae5",
   "metadata": {
    "id": "a15deae5"
   },
   "source": [
    "### <font color='256D85'> Applying the machine learning algorithm with product description <font> <a id=\"4.c\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb462418",
   "metadata": {},
   "source": [
    "In this next section, we will be applying the Random Forest algorithm on our second model (including product description) and another GridSearchCV with restricted hyper-parameter features to make the model more generalized to capture more false positives. We can adjust the column transformer and define the parameters for the grid search. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b6512",
   "metadata": {},
   "source": [
    "#### Defining our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6152688e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6152688e",
    "outputId": "429b4ac8-e0cf-4c89-f720-7d9316b577ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remainder shape (96519, 62)\n",
      "Test shape (41366, 62)\n"
     ]
    }
   ],
   "source": [
    "#for Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = df_combined[\"trending_asin\"]\n",
    "remainder2, test2  = train_test_split(df_with_desc, test_size=0.3, stratify= y, random_state = 8)\n",
    "print(f\"Remainder shape {remainder2.shape}\")\n",
    "print(f\"Test shape {test2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c5926af",
   "metadata": {
    "id": "4c5926af"
   },
   "outputs": [],
   "source": [
    "#assigning remainder dataset for X and y \n",
    "y_remainder2 = remainder2[\"trending_asin\"]\n",
    "X_remainder2  = remainder2.drop([\"trending_asin\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06b91b0c",
   "metadata": {
    "id": "06b91b0c"
   },
   "outputs": [],
   "source": [
    "#assigning test dataset for X and y \n",
    "y_test2 = test2[\"trending_asin\"]\n",
    "X_test2  = test2.drop([\"trending_asin\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45a6f8c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45a6f8c2",
    "outputId": "13429afc-96ee-4c30-91fc-8261ed88f716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (67563, 61)\n",
      "Validation shape (28956, 61)\n"
     ]
    }
   ],
   "source": [
    "#for train/validation split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(X_remainder2, y_remainder2, test_size=0.3, random_state=2, stratify=y_remainder2)\n",
    "print(f\"Train shape {X_train2.shape}\")\n",
    "print(f\"Validation shape {X_val2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3437e26",
   "metadata": {},
   "source": [
    "##### Column Transformer, Pipeline, and Param Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d83ec9",
   "metadata": {},
   "source": [
    "In the adjusted column transformer there is a second line for product_description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6c3fe27",
   "metadata": {
    "id": "e6c3fe27"
   },
   "outputs": [],
   "source": [
    "#column transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "ct_train2 = ColumnTransformer([\n",
    "        ('r_tfidf', TfidfVectorizer(stop_words=\"english\"), 'reviewText'),\n",
    "        ('d_tfidf', TfidfVectorizer(stop_words=\"english\"), 'product_description')\n",
    "    ],\n",
    "        remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8657b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a directory to cache the pipeline results\n",
    "cachedir = mkdtemp()\n",
    "\n",
    "#pipeline steps according to tranform, pca, scale, \n",
    "pipe_rf2 = [('transform', ct_train2),\n",
    "           ('clf', RandomForestClassifier(n_jobs = 1))]\n",
    "\n",
    "pipe = Pipeline(pipe_rf2,verbose=4, memory=cachedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9272741",
   "metadata": {},
   "source": [
    "For the adjusted hyper-parameter grid, there are a couple of things that we want to adjust to produce a more generalized model: \n",
    "- **n_estimators**: We can increase the number of trees\n",
    "- **max_depth**: Decrease the max_depth of each tree so it can prevent the model from overfitting. \n",
    "- **min_samples_leaf**: Introduce this feature since setting a higher value for minimum samples per leaf can help prevent overfitting by restricting the tree's ability to fit the noise in the training data.\n",
    "\n",
    "We also want to save the .csv file of our results so we can evaluate this closer since choosing the best estimator isn't what we are aiming for here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1cc1964",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid2 = [\n",
    "    # Random Forest without PCA\n",
    "    {'transform__r_tfidf__min_df' : [0.03],\n",
    "     'transform__r_tfidf__max_features': [200],\n",
    "     'transform__d_tfidf__min_df' : [0.03,0.4],\n",
    "     'transform__d_tfidf__max_features': [500],\n",
    "     'clf': [RandomForestClassifier(n_jobs = 1)],\n",
    "     'clf__max_depth': [20,25,30],\n",
    "     'clf__n_estimators':[500,600,700],\n",
    "     'clf__min_samples_leaf' : [1]\n",
    "     }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23531a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Persisting input arguments took 0.86s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.983 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Persisting input arguments took 0.86s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.985 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=  11.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Persisting input arguments took 0.86s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.982 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=  11.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Persisting input arguments took 0.86s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.985 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=  11.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Persisting input arguments took 0.86s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.983 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Persisting input arguments took 0.83s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.0min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.974 total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=  11.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Persisting input arguments took 0.83s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  51.1s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.978 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Persisting input arguments took 0.83s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  46.2s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.974 total time= 1.1min\n",
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Persisting input arguments took 0.84s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  49.6s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.977 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=  11.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Persisting input arguments took 0.84s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  46.6s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.975 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.4min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.984 total time= 1.5min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.4min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.982 total time= 1.5min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.4min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.982 total time= 1.5min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.4min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.984 total time= 1.5min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.4min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.981 total time= 1.5min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  55.8s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.976 total time= 1.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  58.9s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.979 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  55.4s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.977 total time= 1.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  58.9s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.980 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  55.1s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.974 total time=  59.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.983 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.984 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.984 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.985 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.6min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.982 total time= 1.7min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.975 total time= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.978 total time= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.976 total time= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.978 total time= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=20, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.974 total time= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.4min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.993 total time= 1.5min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.4min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.993 total time= 1.5min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.4min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.992 total time= 1.5min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.4min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.993 total time= 1.5min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.4min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.991 total time= 1.5min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  49.0s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.991 total time=  53.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  52.2s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.992 total time=  56.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  48.7s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.990 total time=  53.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  51.5s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.993 total time=  56.1s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  48.6s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.992 total time=  53.3s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.992 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.993 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.992 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.992 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.990 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  58.9s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.992 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.0min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.992 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  58.1s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.990 total time= 1.0min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.0min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.993 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  58.5s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.991 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.0min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.992 total time= 2.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.0min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.993 total time= 2.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.0min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.992 total time= 2.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.0min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.993 total time= 2.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.0min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.991 total time= 2.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.991 total time= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.992 total time= 1.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.989 total time= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.992 total time= 1.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=25, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.992 total time= 1.2min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.997 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.998 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.996 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.998 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.7min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.995 total time= 1.8min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  50.1s\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.997 total time=  54.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  53.2s\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.997 total time=  58.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  50.2s\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.996 total time=  54.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  53.3s\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.997 total time=  58.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  50.2s\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=500, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.997 total time=  54.8s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.0min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.998 total time= 2.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.0min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.998 total time= 2.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.0min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.996 total time= 2.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.0min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.997 total time= 2.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.0min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.997 total time= 2.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.0min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.997 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.998 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.0min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.996 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.1min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.998 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.0min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=600, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.997 total time= 1.1min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.3min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.998 total time= 2.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.3min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.998 total time= 2.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.3min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.996 total time= 2.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.3min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.997 total time= 2.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.3min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.03, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.997 total time= 2.4min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 1/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.997 total time= 1.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 2/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.998 total time= 1.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 3/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.996 total time= 1.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 4/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.997 total time= 1.3min\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 1.2min\n",
      "[CV 5/5] END clf=RandomForestClassifier(n_jobs=1), clf__max_depth=30, clf__min_samples_leaf=1, clf__n_estimators=700, transform__d_tfidf__max_features=500, transform__d_tfidf__min_df=0.4, transform__r_tfidf__max_features=200, transform__r_tfidf__min_df=0.03;, score=0.997 total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 2) Processing transform, total=  14.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Persisting input arguments took 1.07s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 2.5min\n"
     ]
    }
   ],
   "source": [
    "#more refined grid search to total train set \n",
    "rf_gs2 = GridSearchCV(estimator = pipe, \n",
    "                    param_grid = rf_param_grid2, \n",
    "                    cv=5, \n",
    "                    n_jobs=1,\n",
    "                    verbose = 4,\n",
    "                    refit=True,\n",
    "                    scoring = 'f1_micro')\n",
    "\n",
    "fitted_rf_gs2 = rf_gs2.fit(X_remainder2, y_remainder2)\n",
    "\n",
    "grid_search_results = fitted_rf_gs2.cv_results_\n",
    "\n",
    "best_estimator = fitted_rf_gs2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6812fc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_results_model_2.csv has been saved to deliverable-slo-bstn-bucket\n"
     ]
    }
   ],
   "source": [
    "#calling the save function\n",
    "write_results_to_s3(grid_search_results, 'rf_results_model_2.csv', 'deliverable-slo-bstn-bucket', 'rf_results_model_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee45bdf5",
   "metadata": {},
   "source": [
    "After having analyzed the results from the csv file we will apply some more generalized hyper parameters to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39424300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the output after vectorization is: (67563, 657)\n"
     ]
    }
   ],
   "source": [
    "#column transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "ct_train2 = ColumnTransformer([\n",
    "        ('r_tfidf', TfidfVectorizer(stop_words=\"english\",min_df=0.03,max_features=1000), 'reviewText'),\n",
    "        ('d_tfidf', TfidfVectorizer(stop_words=\"english\",min_df=0.04,max_features=1000), 'product_description')\n",
    "    ],\n",
    "        remainder='passthrough'\n",
    ")\n",
    "\n",
    "# 2. Fit \n",
    "ct_train2.fit(X_train2,y_train2)\n",
    "\n",
    "# 3. Transform\n",
    "X_train_tfidf_rf2 = ct_train2.transform(X_train2)\n",
    "X_val_tfidf_rf2 = ct_train2.transform(X_val2)\n",
    "X_test_tfidf_rf2 = ct_train2.transform(X_test2)\n",
    "print(f\"Shape of the output after vectorization is: {X_train_tfidf_rf2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d167f400",
   "metadata": {},
   "source": [
    "The shape output of model two isn't looking the best at 657 columns, this may make the model too complex and actually cause over-fitting which is not what we intended to do. Let's plot this out with a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71cc7c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=25, max_features=0.2, n_estimators=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=25, max_features=0.2, n_estimators=500)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=25, max_features=0.2, n_estimators=500)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate the model\n",
    "rf = RandomForestClassifier(n_estimators = 500, \n",
    "                            max_features = 0.2, \n",
    "                            max_depth = 25\n",
    ")\n",
    "#fit\n",
    "rf.fit(X_train_tfidf_rf2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e38982f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Random Forest Confusion Matrix')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion Matrix Random Forest\n",
    "ConfusionMatrixDisplay.from_estimator(rf, X_val_tfidf_rf2, y_val2)\n",
    "plt.title('Random Forest Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951b2fa8",
   "metadata": {
    "id": "4653773f"
   },
   "source": [
    "From taking a look at the confusion matrix we can clearly see that we have no false positives and worse results in general, in fact making the model more complex by adding in the product description column makes performance worse. Sometimes it's better to stick with your first model and keep things more simple. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e154522b",
   "metadata": {},
   "source": [
    "### <font color='256D85'> The Final Model <font> <a id=\"4.d\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8ad102",
   "metadata": {},
   "source": [
    "After having taken a mini detour with model 2 we can now evaluate our original model which is our model which just contains the `reviewText` column. To finish let's evaluate our model against the test set that we've reserved for the very end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "03967a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the output after vectorization is: (67563, 126)\n"
     ]
    }
   ],
   "source": [
    "#count vectorizer function\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "\n",
    "ct_train_rf = ColumnTransformer([\n",
    "        ('tfidf', TfidfVectorizer(stop_words=\"english\",min_df=0.03,max_features=1000), 'reviewText')\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# 2. Fit \n",
    "ct_train_rf.fit(X_train1,y_train1)\n",
    "\n",
    "# 3. Transform\n",
    "X_train_tfidf_rf = ct_train_rf.transform(X_train1)\n",
    "X_val_tfidf_rf = ct_train_rf.transform(X_val1)\n",
    "X_test_tfidf_rf = ct_train_rf.transform(X_test1)\n",
    "print(f\"Shape of the output after vectorization is: {X_train_tfidf_rf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "66818fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### CLASSIFICATION REPORT FOR RANDOM FOREST MODEL 1 #######\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     36756\n",
      "           1       0.98      0.98      0.98      4610\n",
      "\n",
      "    accuracy                           1.00     41366\n",
      "   macro avg       0.99      0.99      0.99     41366\n",
      "weighted avg       1.00      1.00      1.00     41366\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Final Matrix Random Forest\n",
    "ConfusionMatrixDisplay.from_estimator(rf, X_test_tfidf_rf, y_test1)\n",
    "plt.title('Random Forest Confusion Matrix')\n",
    "\n",
    "#classification report for Random Forest\n",
    "print(\"###### CLASSIFICATION REPORT FOR RANDOM FOREST MODEL 1 #######\")\n",
    "y_pred = rf.predict(X_test_tfidf_rf)\n",
    "print(classification_report(y_test1, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8a1212",
   "metadata": {},
   "source": [
    "These numbers are looking pretty good against the test set, we achieved a 98% F1-micro score against our target column! So the fears of over-fitting didn't come to fruition, we still have a higher number of false negatives than positives, but these are fairly balanced still, what is great is that all of the feature engineering and cleaning we did at the start of this notebook seemed to pay off when it came to modelling. Let's summarize our final model parameters below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe728c5",
   "metadata": {},
   "source": [
    "| **Final Model** | **F1-Micro Score on Test (Trending)** | **Best Parameters TFIDF**          | **Best Parameters Model**                                 |\n",
    "|-----------------|-----------------------------|------------------------------------|-----------------------------------------------------------|\n",
    "| Random Forest       | 98%                      | [min_df=0.03, max_features = 1000] | [n_estimators = 500, max_depth = 40 , max_features = 0.2] |\n",
    "| Baseline        | 89%                      | -------------------                | ------------------------                                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bb5d3a",
   "metadata": {
    "id": "95bb5d3a"
   },
   "source": [
    "##  <font color='256D85'> Conclusion to this notebook <font> <a id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49a1ec",
   "metadata": {},
   "source": [
    "Throughout this notebook, we have explored four different machine learning algorithms and evaluated the best two models by using confusion matrices and feature importance. Finally, we tried to make the model more generalizable by performing some hyper-parameter tuning but we learned that sometimes the first model is the best. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2b1f24",
   "metadata": {},
   "source": [
    "### <font color='256D85'> Final Thoughts on the project <font> <a id=\"5.a\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c66156",
   "metadata": {},
   "source": [
    "The main goal of this project was to create a Trend Searcher at the product level, since it could bring a greater level of proof for companies or stakeholder working in new product development or advertising. Personally, I think that we accomplished the needs for this project by predicting which products were trending so I would be excited to apply this (with some new hyper-parameter tuning) to fresh data. Some next steps that I would want to incorporate are to: \n",
    "\n",
    "- Add more evaluation metrics such as the shapley value to see if this would improve the result\n",
    "- Remove the ranking feature and discover if the model can produce accurate results without this value. Although it is an intuitive metric to play larger feature importance, this was only found at the very end of the modelling process. \n",
    "\n",
    "Thank you for taking the time to read through this project, I truly enjoyed the entire process and personally learnt a great deal (whilst also having dedicated time to carry out side research on some skincare brands!). "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "b06bea1f055e9e6a60b83a241ca3234f09eb239600d1f1bcf010f291275670df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
